{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **NLP를 위한 딥 러닝 개요(Deep Learning for NLP)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **퍼셉트론(Perceptron)**\n",
    "인공 신경망은 수많은 머신 러닝 방법 중 하나입니다. 하지만 최근 인공 신경망을 복잡하게 쌓아 올린 딥 러닝이 다른 머신 러닝 방법들을 뛰어넘는 성능을 보여주는 사례가 늘면서, 전통적인 머신 러닝과 딥 러닝을 구분해서 이해해야 한다는 목소리가 커지고 있습니다. 딥 러닝을 이해하기 위해서는 우선 인공 신경망에 대한 이해가 필요한데, 이번 챕터에서는 초기의 인공 신경망인 퍼셉트론(Perceptron)에 대해서 이해합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. 퍼셉트론(Perceptron)**\n",
    "\n",
    "퍼셉트론(Perceptron)은 프랑크 로젠블라트(Frank Rosenblatt)가 1957년에 제안한 초기 형태의 인공 신경망으로 다수의 입력으로부터 하나의 결과를 내보내는 알고리즘입니다. 퍼셉트론은 실제 뇌를 구성하는 신경 세포 뉴런의 동작과 유사한데, 신경 세포 뉴런의 그림을 먼저 보도록 하겠습니다. 뉴런은 가지돌기에서 신호를 받아들이고, 이 신호가 일정치 이상의 크기를 가지면 축삭돌기를 통해서 신호를 전달합니다.\n",
    "\n",
    "![img](https://wikidocs.net/images/page/24958/%EB%89%B4%EB%9F%B0.PNG)\n",
    "\n",
    "이제 다수의 입력을 받는 퍼셉트론의 그림을 보겠습니다. 신경 세포 뉴런의 입력 신호와 출력 신호가 퍼셉트론에서 각각 입력값과 출력값에 해당됩니다.\n",
    "\n",
    "![img](https://wikidocs.net/images/page/24958/perceptrin1_final.PNG)\n",
    "\n",
    "$x$는 입력값을 의미하며, $W$는 가중치(Weight), $y$는 출력값입니다. 그림 안의 원은 인공 뉴런에 해당됩니다. 실제 신경 세포 뉴런에서의 신호를 전달하는 축삭돌기의 역할을 퍼셉트론에서는 가중치가 대신합니다. 각각의 인공 뉴런에서 보내진 입력값 $x$는 각각의 가중치 $W$와 함께 종착지인 인공 뉴런에 전달되고 있습니다.\n",
    "\n",
    "***각각의 입력값에는 각각의 가중치가 존재하는데, 이때 가중치의 값이 크면 클수록 해당 입력 값이 중요하다는 것을 의미합니다.***\n",
    "\n",
    "각 입력값이 가중치와 곱해져서 인공 뉴런에 보내지고, 각 입력값과 그에 해당되는 가중치의 곱의 전체 합이 임계치(threshold)를 넘으면 종착지에 있는 인공 뉴런은 출력 신호로서 1을 출력하고, 그렇지 않을 경우에는 0을 출력합니다. 이러한 함수를 계단 함수(Step function)라고 하며, 아래는 그래프는 계단 함수의 하나의 예를 보여줍니다.\n",
    "\n",
    "![img](https://wikidocs.net/images/page/24987/step_function.PNG)\n",
    "\n",
    "이때 계단 함수에 사용된 이 임계치값을 수식으로 표현할 때는 보통 세타(Θ)로 표현합니다. 이를 식으로 표현하면 다음과 같습니다. <br>\n",
    "$$\n",
    "if \\sum_i^{n} W_{i}x_{i}\\ ≥ \\theta → y=1\n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "if \\sum_i^{n} W_{i}x_{i}\\ < \\theta → y=0\n",
    "$$\n",
    "<br>\n",
    "\n",
    "단, 위의 식에서 임계치를 좌변으로 넘기고 편향 bb(bias)로 표현할 수도 있습니다. 편향 bb 또한 퍼셉트론의 입력으로 사용됩니다. 보통 그림으로 표현할 때는 입력값이 1로 고정되고 편향 bb가 곱해지는 변수로 표현됩니다.\n",
    "\n",
    "![img](https://wikidocs.net/images/page/24958/perceptron2_final.PNG)\n",
    "\n",
    "<br>\n",
    "$$\n",
    "if \\sum_i^{n} W_{i}x_{i} + b ≥ 0 → y=1\n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "if \\sum_i^{n} W_{i}x_{i} + b < 0 → y=0\n",
    "$$\n",
    "<br>\n",
    "이 책을 포함한 많은 인공 신경망 자료에서 편의상 편향 b가 그림이나 수식에서 생략되서 표현되기도 하지만 실제로는 편향 b 또한 딥 러닝이 최적의 값을 찾아야 할 변수 중 하나입니다.\n",
    "\n",
    "다음 챕터에서 배우겠지만 이렇게 ***뉴런에서 출력값을 변경시키는 함수를 활성화 함수(Activation Function)라고 합니다.*** 초기 인공 신경망 모델인 퍼셉트론은 활성화 함수로 계단 함수를 사용하였지만, 그 뒤에 등장한 여러가지 발전된 신경망들은 계단 함수 외에도 여러 다양한 활성화 함수를 사용하기 시작했습니다. 사실 앞서 배운 시그모이드 함수나 소프트맥스 함수 또한 활성화 함수 중 하나입니다.\n",
    "\n",
    "퍼셉트론을 배우기 전에 로지스틱 회귀를 먼저 배운 이유도 여기에 있습니다. 퍼셉트론의 활성화 함수는 계단 함수이지만 여기서 활성화 함수를 시그모이드 함수로 변경하면 방금 배운 퍼셉트론은 곧 이진 분류를 수행하는 로지스틱 회귀와 동일함을 알 수 있습니다.\n",
    "\n",
    "다시 말하면 로지스틱 회귀 모델이 인공 신경망에서는 하나의 인공 뉴런으로 볼 수 있습니다. 로지스틱 회귀를 수행하는 인공 뉴런과 위에서 배운 퍼셉트론의 차이는 오직 활성화 함수의 차이입니다.\n",
    "\n",
    "- 인공 뉴런 : 활성화 함수 $f(\\sum_i^{n} W_{i}x_{i} + b)$\n",
    "- 위의 퍼셉트론(인공 뉴런 종류 중 하나) : 계단 함수 $f(\\sum_i^{n} W_{i}x_{i} + b)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **2. 단층 퍼셉트론(Single-Layer Perceptron)**\n",
    "\n",
    "위에서 배운 퍼셉트론을 단층 퍼셉트론이라고 합니다. 퍼셉트론은 단층 퍼셉트론과 다층 퍼셉트론으로 나누어지는데, ***단층 퍼셉트론은 값을 보내는 단계과 값을 받아서 출력하는 두 단계로만 이루어집니다.*** 이때 이 각 단계를 보통 층(layer)라고 부르며, 이 두 개의 층을 입력층(input layer)과 출력층(output layer)이라고 합니다.\n",
    "\n",
    "![img](https://wikidocs.net/images/page/24958/perceptron3_final.PNG)\n",
    "\n",
    "단층 퍼셉트론의 한계를 개선하기 위해 향후에 나온 다층 퍼셉트론을 배우게 되면 단층과 다층 이 두 퍼셉트론이 어떤 차이를 가지는지 쉽게 이해할 수 있습니다. 단층 퍼셉트론이 어떤 일을 할 수 있으며 한계는 무엇인지 학습해보겠습니다.\n",
    "\n",
    "***단층 퍼셉트론을 이용하면 AND, NAND, OR 게이트를 쉽게 구현할 수 있습니다.*** 게이트 연산에 쓰이는 것은 두 개의 입력값과 하나의 출력값입니다. 예를 들어 AND 게이트의 경우에는 두 개의 입력 값이 모두 1인 경우에만 출력값이 1이 나오는 구조를 갖고 있습니다.\n",
    "\n",
    "![img](https://wikidocs.net/images/page/24958/andgate.PNG)\n",
    "\n",
    "단층 퍼셉트론의 식을 통해 AND 게이트를 만족하는 두 개의 가중치와 편향 값에는 뭐가 있을까요? 각각 $w_{1}$, $w_{2}$, $b$라고 한다면 [0.5, 0.5, -0.7], [0.5, 0.5, -0.8] 또는 [1.0, 1.0, -1.0] 등 이 외에도 다양한 가중치와 편향의 조합이 나올 수 있습니다. 이해를 돕기 위해서 AND 게이트를 위한 매개변수 값을 가진 단층 퍼셉트론의 식을 파이썬 코드로 간단하게 구현해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AND_gate(x1, x2):\n",
    "    w1=0.5\n",
    "    w2=0.5\n",
    "    b=-0.7\n",
    "    result = x1*w1 + x2*w2 + b\n",
    "    if result <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 함수에 AND 게이트의 입력값을 모두 넣어보면 오직 두 개의 입력값이 1인 경우에만 1을 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AND_gate(0, 0), AND_gate(0, 1), AND_gate(1, 0), AND_gate(1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그렇다면 두 개의 입력값이 1인 경우에만 출력값이 0, 나머지 입력값의 쌍(pair)에 대해서는 모두 출력값이 1이 나오는 NAND 게이트는 어떨까요?\n",
    "\n",
    "![img](https://wikidocs.net/images/page/24958/nandgate.PNG)\n",
    "\n",
    "앞서 언급했던 ***AND 게이트를 충족하는 가중치와 편향값인 [0.5, 0.5, -0.7]에 -를 붙여서 [-0.5, -0.5, +0.7]을 단층 퍼셉트론의 식에 넣어보면 NAND 게이트를 충족***합니다. 파이썬 코드를 통해서 이를 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NAND_gate(x1, x2):\n",
    "    w1=-0.5\n",
    "    w2=-0.5\n",
    "    b=0.7\n",
    "    result = x1*w1 + x2*w2 + b\n",
    "    if result <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단지 같은 코드에 함수 이름과 가중치와 편향만 바꿨을 뿐입니다. 퍼셉트론의 구조는 같기때문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 1, 0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NAND_gate(0, 0), NAND_gate(0, 1), NAND_gate(1, 0), NAND_gate(1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAND 게이트를 구현한 파이썬 코드에 입력값을 넣자, 두 개의 입력값이 1인 경우에만 0이 나오는 것을 확인할 수 있습니다. 퍼셉트론으로 NAND 게이트를 구현한 것입니다. [-0.5, -0.5, -0.7] 외에도 퍼셉트론이 NAND 게이트의 동작을 하도록 하는 다양한 가중치와 편향의 값들이 있을 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 개의 입력이 모두 0인 경우에 출력값이 0이고 나머지 경우에는 모두 출력값이 1인 OR 게이트 또한 적절한 가중치 값과 편향 값만 찾으면 단층 퍼셉트론의 식으로 구현할 수 있습니다.\n",
    "\n",
    "![img](https://wikidocs.net/images/page/24958/orgate.PNG)\n",
    "\n",
    "예를 들어 각각 가중치와 편향에 대해서 [0.6, 0.6, -0.5]를 선택하면 OR 게이트를 충족합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OR_gate(x1, x2):\n",
    "    w1=0.6\n",
    "    w2=0.6\n",
    "    b=-0.5\n",
    "    result = x1*w1 + x2*w2 + b\n",
    "    if result <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 1, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OR_gate(0, 0), OR_gate(0, 1), OR_gate(1, 0), OR_gate(1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "물론, 이 외에도 이를 충족하는 다양한 가중치와 편향의 값이 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이처럼 단층 퍼셉트론은 AND 게이트, NAND 게이트, OR 게이트 또한 구현할 수 있습니다. 하지만 단층 퍼셉트론으로 구현이 불가능한 게이트가 있는데 바로 XOR 게이트입니다. XOR 게이트는 입력값 두 개가 서로 다른 값을 갖고 있을때에만 출력값이 1이 되고, 입력값 두 개가 서로 같은 값을 가지면 출력값이 0이 되는 게이트입니다. 위의 파이썬 코드에 아무리 수많은 가중치와 편향을 넣어봐도 XOR 게이트를 구현하는 것은 불가능합니다. 그 이유는 단층 퍼셉트론은 직선 하나로 두 영역을 나눌 수 있는 문제에 대해서만 구현이 가능하기 때문입니다.\n",
    "\n",
    "예를 들어 AND 게이트에 대한 단층 퍼셉트론을 시각화해보면 다음과 같습니다.\n",
    "\n",
    "![img](https://wikidocs.net/images/page/24958/andgraphgate.PNG)\n",
    "\n",
    "그림에서는 출력값 0을 하얀색 원, 1을 검은색 원으로 표현했습니다. AND 게이트를 충족하려면 하얀색 원과 검은색 원을 직선으로 나누게 됩니다. 마찬가지로 NAND 게이트나 OR 게이트에 대해서도 시각화를 했을 때 직선으로 나누는 것이 가능합니다.\n",
    "\n",
    "![img](https://wikidocs.net/images/page/24958/oragateandnandgate.PNG)\n",
    "\n",
    "그렇다면 XOR 게이트는 어떨까요? XOR 게이트는 입력값 두 개가 서로 다른 값을 갖고 있을때에만 출력값이 1이 되고, 입력값 두 개가 서로 같은 값을 가지면 출력값이 0이 되는 게이트입니다. XOR 게이트를 시각화해보면 다음과 같습니다.\n",
    "\n",
    "![img](https://wikidocs.net/images/page/24958/xorgraphandxorgate.PNG)\n",
    "\n",
    "하얀색 원과 검은색 원을 직선 하나로 나누는 것은 불가능합니다. 즉, 단층 퍼셉트론으로는 XOR 게이트를 구현하는 것이 불가능합니다. 이를 단층 퍼셉트론은 선형 영역에 대해서만 분리가 가능하다고 말합니다. 다시 말하면 XOR 게이트는 직선이 아닌 곡선. 비선형 영역으로 분리하면 구현이 가능합니다.\n",
    "\n",
    "![img](https://wikidocs.net/images/page/24958/xorgate_nonlinearity.PNG)\n",
    "\n",
    "위의 그림은 곡선을 사용한다면 하얀색 원과 검은색 원을 나눌 수 있음을 보여줍니다. 이제 XOR 게이트를 만들 수 있는 다층 퍼셉트론에 대해서 알아보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. 다층 퍼셉트론(Multi-Layer Perceptron, MLP)**\n",
    "\n",
    "XOR 게이트는 기존의 AND, NAND, OR 게이트를 조합하면 만들 수 있습니다. 퍼셉트론 관점에서 말하면, 층을 더 쌓으면 만들 수 있습니다. 다층 퍼셉트론과 단층 퍼셉트론의 차이는 단층 퍼셉트론은 입력층과 출력층만 존재하지만, 다층 퍼셉트론은 중간에 층을 더 추가하였다는 점입니다. 이렇게 입력층과 출력층 사이에 존재하는 층을 은닉층(hidden layer)이라고 합니다. 즉, 다층 퍼셉트론은 중간에 은닉층이 존재한다는 점이 단층 퍼셉트론과 다릅니다. 다층 퍼셉트론은 줄여서 MLP라고도 부릅니다.\n",
    "\n",
    "![img](https://wikidocs.net/images/page/24958/perceptron_4image.jpg)\n",
    "\n",
    "위의 그림은 AND, NAND, OR 게이트를 조합하여 XOR 게이트를 구현한 다층 퍼셉트론의 예입니다. (실제 구현은 숙제로 남겨두겠습니다. 힌트를 드리자면 위의 단층 퍼셉트론에서 사용한 함수들을 그대로 사용하면 됩니다.) XOR 예제에서는 은닉층 1개만으로 문제를 해결할 수 있었지만, ***다층 퍼셉트론은 본래 은닉층이 1개 이상인 퍼셉트론을 말합니다.*** 즉, XOR 문제보다 더욱 복잡한 문제를 해결하기 위해서 다층 퍼셉트론은 중간에 수많은 은닉층을 더 추가할 수 있습니다. 은닉층의 개수는 2개일 수도 있고, 수십 개일수도 있고 사용자가 설정하기 나름입니다. 아래는 더 어려운 문제를 풀기 위해서 은닉층이 하나 더 추가되고(이 경우에는 은닉층이 2개), 뉴런의 개수를 늘린 다층 퍼셉트론의 모습을 보여줍니다.\n",
    "\n",
    "![img](https://wikidocs.net/images/page/24958/%EC%9E%85%EC%9D%80%EC%B8%B5.PNG)\n",
    "\n",
    "위와 같이 은닉층이 2개 이상인 신경망을 심층 신경망(Deep Neural Network, DNN)이라고 합니다. 심층 신경망은 다층 퍼셉트론만 이야기 하는 것이 아니라, 여러 변형된 다양한 신경망들도 은닉층이 2개 이상이 되면 심층 신경망이라고 합니다.\n",
    "\n",
    "그리고 지금까지는 OR 게이트, AND 게이트, XOR 게이트 등. 퍼셉트론이 가야할 정답지를 보면서 퍼셉트론이 정답을 출력할 때까지 가중치를 이것, 저것 바꿔보면서 맞는 가중치를 찾았습니다. 즉, 가중치를 수동으로 찾았습니다. 하지만 이제는 기계가 가중치를 스스로 찾아내도록 자동화시켜야하는데, 이것이 머신 러닝에서 말하는 학습(training) 단계에 해당됩니다. 앞서 선형 회귀와 로지스틱 회귀에서 보았듯이 손실 함수(Loss function)와 옵티마이저(Optimizer)를 사용합니다. 그리고 만약 학습을 시키는 인공 신경망이 심층 신경망일 경우에는 이를 심층 신경망을 학습시킨다고 하여, **딥 러닝(Deep Learning)**이라고 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# **인공 신경망(Artificial Neural Network) 훑어보기**\n",
    "\n",
    "인공 신경망(Artificial Neural Network)이 발전함에 따라, 앞서 배운 퍼셉트론의 틀을 벗어나 계단 함수(Step funtion)가 아닌 다른 활성화 함수가 도입되고, 은닉층의 구조를 좀 더 복잡하게 해보는 등 다양한 시도로 새로운 인공 신경망들이 등장하기 시작했습니다. 이번 챕터에서는 계단 함수 대신 선택할 수 있는 활성화 함수들과 인공 신경망의 행렬 연산을 이용한 순전파에 대해서 이해해봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **1. 피드 포워드 신경망(Feed-Forward Neural Network, FFNN)**\n",
    "\n",
    "앞서 배운 단층 퍼셉트론이나 다층 퍼셉트론과 같이 입력층에서 출력층 방향으로 연산이 전개되는 신경망을 피드 포워드 신경망이라고 합니다. 줄여서 FFNN이라고도 합니다. 이렇게 별도로 정의되는 이유는 FFNN이 아닌 신경망이 존재하기 때문입니다.\n",
    "\n",
    "![img](https://wikidocs.net/images/page/24987/rnn_image1_%EC%88%98%EC%A0%95.PNG)\n",
    "\n",
    "위의 그림은 대표적으로 FFNN이 아닌 RNN이라는 신경망을 보여줍니다. 이 신경망은 은닉층의 출력값을 출력층으로도 값을 보내지만, 동시에 은닉층의 출력값이 다시 은닉층의 입력으로 사용되는데 이는 FFNN의 정의에 벗어납니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **2. 전결합층(Fully-connected layer, FC, Dense layer)**\n",
    "\n",
    "앞서 본 다층 퍼셉트론은 은닉층과 출력층에 있는 모든 뉴런은 바로 이전 층의 모든 뉴런과 연결돼 있었습니다. 그와 같이 ***어떤 층의 모든 뉴런이 이전 층의 모든 뉴런과 연결돼 있는 층을 전결합층***이라고 합니다. 줄여서 FC라고 부르기도 합니다.\n",
    "\n",
    "즉, 앞서 본 다층 퍼셉트론의 모든 은닉층과 출력층은 전결합층입니다. 이와 동일한 의미로 **밀집층(Dense layer)**이라고 부르기도 하는데, 케라스에서는 밀집층을 구현할 때 Dense()를 사용합니다. 자세한 구현 방법은 뒤에서 배웁니다.\n",
    "\n",
    "만약 전결합층만으로 구성된 피드 포워드 신경망이 있다면, 이를 전결합 피드 포워드 신경망(Fully-connected FFNN)이라고도 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **3. 활성화 함수(Activation Function)**\n",
    "\n",
    "![img](https://wikidocs.net/images/page/24987/activation_function_final.PNG)\n",
    "\n",
    "앞서 배운 퍼셉트론에서는 계단 함수(Step function)를 통해 출력값이 0이 될지, 1이 될지를 결정했습니다. 이러한 매커니즘은 실제 뇌를 구성하는 신경 세포 뉴런이 전위가 일정치 이상이 되면 시냅스가 서로 화학적으로 연결되는 모습을 모방한 것입니다. 이렇게 은닉층과 출력층의 뉴런에서 출력값을 결정하는 함수를 활성화 함수(Activation function)라고 하는데 계단 함수는 이러한 활성화 함수의 하나의 예제에 불과합니다.\n",
    "\n",
    "앞으로 다양한 활성화 함수에 대해서 알아볼텐데, 사실 일부는 7챕터인 머신 러닝 챕터에서 이미 봤던 함수들입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(1) 활성화 함수의 특징 - 비선형 함수(Nonlinear function)**\n",
    "\n",
    "활성화 함수의 특징은 선형 함수가 아닌 비선형 함수여야 한다는 점입니다. 선형 함수란 출력이 입력의 상수배만큼 변하는 함수를 선형함수라고 합니다. 예를 들어 $f(x) = Wx + b$라는 함수가 있을 때, W와 b는 상수입니다. 이 식은 그래프를 그리면 직선이 그려집니다. 반대로 비선형 함수는 직선 1개로는 그릴 수 없는 함수를 말합니다.\n",
    "\n",
    "인공 신경망에서 활성화 함수는 반드시 비선형 함수여야 합니다. 앞서 퍼셉트론에서도 계단 함수라는 활성화 함수를 사용했습니다. 즉, 계단 함수 또한 비선형 함수에 속합니다.\n",
    "\n",
    "인공 신경망의 능력을 높이기 위해서는 은닉층을 계속해서 추가해야 합니다. 그런데 만약 활성화 함수로 선형 함수를 사용하게 되면 은닉층을 쌓을 수가 없습니다. 예를 들어 활성화 함수로 선형 함수를 선택하고, 층을 계속 쌓는다고 가정해보겠습니다. 활성화 함수는 $f(x) = Wx$라고 가정합니다. 여기다가 은닉층을 두 개 추가한다고하면 출력층을 포함해서 $y(x) = f(f(f(x)))$가 됩니다. 이를 식으로 표현하면 $W × W × W × x$입니다. 그런데 이는 잘 생각해보면 $W$의 세 제곱값을 $k$라고 정의해버리면 $y(x) = kx$와 같이 다시 표현이 가능합니다. ***즉, 선형 함수로는 은닉층을 여러번 추가하더라도 1회 추가한 것과 차이를 줄 수 없습니다.***\n",
    "\n",
    "선형 함수를 사용한 은닉층을 1회 추가한 것과 연속으로 추가한 것이 차이가 없다는 뜻이지, 선형 함수를 사용한 층이 아무 의미가 없다는 뜻이 아닙니다. 학습 가능한 가중치가 새로 생긴다는 점에서 분명히 의미가 있습니다. 이와 같이 선형 함수를 사용한 층을 활성화 함수를 사용하는 은닉층과 구분하기 위해서 선형층(linear layer)이나 투사층(projection layer) 등의 다른 표현을 사용하여 표현하기도 합니다. 활성화 함수를 사용하는 일반적인 은닉층을 선형층과 대비되는 표현을 사용하면 비선형층(nonlinear layer)입니다.\n",
    "\n",
    "파이썬을 통해 주로 사용되는 활성화 함수를 직접 그려보고, 이해해보도록 하겠습니다. 아래의 모든 코드는 앞서 아래의 코드가 먼저 수행되었다고 가정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # 넘파이 사용\n",
    "import matplotlib.pyplot as plt # 맷플롯립 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(2) 계단 함수(Step function)**\n",
    "\n",
    "![img](https://wikidocs.net/images/page/24987/step_function.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def step(x):\n",
    "    return np.array(x > 0, dtype=np.int)\n",
    "\n",
    "x = np.arange(-5.0, 5.0, 0.1) # -5.0부터 5.0까지 0.1 간격 생성\n",
    "y = step(x)\n",
    "\n",
    "plt.title('Step Function')\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "계단 함수는 이제 거의 사용되지 않지만, 퍼셉트론을 통해 처음으로 인공 신경망을 배울 때 가장 처음 접하게 되는 활성화 함수입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(3) 시그모이드 함수(Sigmoid function)**\n",
    "\n",
    "![img](https://wikidocs.net/images/page/24987/%EC%8B%9C%EA%B7%B8%EB%AA%A8%EC%9D%B4%EB%93%9C_%ED%95%A8%EC%88%98.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "x = np.arange(-5.0, 5.0, 0.1)\n",
    "y = sigmoid(x)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.plot([0,0],[1.0,0.0], ':') # 가운데 점선 추가\n",
    "plt.title('Sigmoid Function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시그모이드 함수는 가중치 곱의 합을 0과 1사이의 값으로 조정하여 반환하는 활성화 함수입니다. 이미 로지스틱 회귀를 통해 접한 바 있는 함수이지만 다시 설명하겠습니다. 시그모이드 함수는 마치 S자의 모양을 연상시키며, 로지스틱 함수(logistic function)라고도 부릅니다. 시그모이드 함수는 특정 목적으로 출력층의 뉴런에서 주로 사용되는데, 두 가지 선택지 중 하나를 고르는 **이진 분류 문제(Binary Classification)**에 사용합니다. 시그모이드 함수는 0과 1사이의 값을 반환합니다.\n",
    "\n",
    "이러한 이진 분류 문제의 예로 입력한 메일에 대해서 정상 메일인지, 스팸 메일인지를 판별하게 하는 예제가 있습니다. 실제로 뒤에서 텍스트 분류 챕터에서도 스팸 메일 분류기를 구현할 때, 출력층의 뉴런에 시그모이드 함수를 사용할 것입니다.\n",
    "\n",
    "시그모이드 함수와 계단 함수는 두 함수 모두 입력이 작을 때 출력이 0에 가까워지고, 입력이 커질 때는 출력이 1에 가까워진다는 점에서는 언뜻 보기에 비슷해보입니다. 즉, 굳이 활성화 함수로 계단 함수 대신 시그모이드 함수를 사용해야하는 이유에 대해서 의문이 생길 수 있습니다. ***계단 함수와 시그모이드 함수의 차이는 계단 함수는 0을 경계로 출력이 급격하게 변하는 것에 비해, 시그모이드 함수는 입력에 따라 출력이 연속적으로 변하는 곡선의 모양을 가진다는 것***입니다. 그런데 이 차이가 신경망 학습에서는 아주 큰 차이를 불러옵니다. 인공 신경망은 역전파(Back Propagation)라는 과정을 통해 인공 신경망에 경사 하강법을 수행하는데, 이때 인공 신경망의 전체 식의 일부에 해당하는 활성화 함수도 미분의 대상이 됩니다. 앞서 배웠듯이 경사 하강법은 접선의 기울기를 이용합니다. 그런데 ***계단 함수는 거의 모든 구간에서 기울기가 0이므로 학습이 제대로 되지 않습니다.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(4) 렐루 함수(Relu function)**\n",
    "\n",
    "![img](https://wikidocs.net/images/page/24987/%EB%A0%90%EB%A3%A8%ED%95%A8%EC%88%98.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "x = np.arange(-5.0, 5.0, 0.1)\n",
    "y = relu(x)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.plot([0,0],[5.0,0.0], ':')\n",
    "plt.title('Relu Function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "은닉층에서 활성화 함수로 가장 많이 사용되는 활성화 함수입니다. 하지만 입력값이 0보다 작을 경우, 미분값이 0이 되는 단점이 존재하는데 이를 보완한 Leaky ReLU와 같은 ReLU의 변형 함수들이 등장하기 시작했습니다. 하지만 그럼에도 여전히 은닉층에서 가장 많이 사용되는 활성화 함수입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(5) 하이퍼볼릭탄젠트 함수(Tanh function)**\n",
    "\n",
    "![img](https://wikidocs.net/images/page/24987/%ED%95%98%EC%9D%B4%ED%8D%BC%EB%B3%BC%EB%A6%AD_%ED%83%84%EC%A0%A0%ED%8A%B8.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(-5.0, 5.0, 0.1) # -5.0부터 5.0까지 0.1 간격 생성\n",
    "y = np.tanh(x)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.plot([0,0],[1.0,-1.0], ':')\n",
    "plt.axhline(y=0, color='orange', linestyle='--')\n",
    "plt.title('Tanh Function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "은닉층에서 활성화 함수로 종종 사용되는 활성화 함수입니다. \n",
    "\n",
    "- 이미지 인식 분야에서 자주 사용되는 인공 신경망인 CNN에서는 ReLu 함수가 주로 사용되고\n",
    "- 자연어 처리 분야에서 자주 사용되는 인공 신경망인 LSTM에서는 tanh 함수와 시그모이드 함수가 주로 사용됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(6) 소프트맥스 함수(Softmax function)**\n",
    "\n",
    "![img](https://wikidocs.net/images/page/24987/%EC%86%8C%ED%94%84%ED%8A%B8%EB%A7%A5%EC%8A%A4_%ED%95%A8%EC%88%98.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(-5.0, 5.0, 0.1) # -5.0부터 5.0까지 0.1 간격 생성\n",
    "y = np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.title('Softmax Function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시그모이드 함수처럼 출력층의 뉴런에서 주로 사용되는데, 시그모이드 함수가 두 가지 선택지 중 하나를 고르는 **이진 분류 (Binary Classification)** 문제에 사용된다면 세 가지 이상의 선택지 중 하나를 고르는 **다중 클래스 분류(MultiClass Classification)** 문제에 주로 사용됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **4. 행렬의 곱셈을 이용한 순전파(Forward Propagation)**\n",
    "\n",
    "![img](https://wikidocs.net/images/page/24987/neuralnetwork.PNG)\n",
    "\n",
    "위와 같은 인공 신경망이 있다고 합시다. 주어진 인공 신경망을 케라스로 구현해본다면 아래와 같이 짧은 코드로 구현할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\young\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, input_dim=4, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential() # 층을 추가할 준비\n",
    "\n",
    "# 입력층(4)과 다음 은닉층(8) 그리고 은닉층의 활성화 함수는 relu\n",
    "model.add(Dense(8, input_dim=4, init='uniform', activation='relu'))\n",
    "\n",
    "model.add(Dense(8, activation='relu')) # 은닉층(8)의 활성화 함수는 relu\n",
    "model.add(Dense(3, activation='softmax')) # 출력층(3)의 활성화 함수는 softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아직 케라스로 인공 신경망 모델을 만드는 방법을 자세히 배우지 않았지만, 사실 위의 코드가 어떤 의미인지 파악하는 것은 어렵지 않습니다. ***위의 코드의 주석에서 () 괄호 안의 값은 각 층에서의 뉴런의 수를 의미하며 입력층부터 출력층까지 순차적으로 인공 신경망의 층을 한 층씩 추가***하였습니다. 케라스를 사용하면 이렇게 간단하게 딥 러닝 모델을 구현할 수 있습니다.\n",
    "\n",
    "인공 신경망에서 입력층에서 출력층 방향으로 연산을 진행하는 과정을 순전파(Forward Propagation)라고 합니다. 다르게 말하면 ***주어진 입력으로부터 예측값을 계산하는 과정을 순전파라고 합니다.*** 앞서 머신 러닝 챕터에서 배웠던 벡터와 행렬 연산을 인공 신경망에 적용하려고 하면, 벡터와 행렬 연산이 순전파 과정에서 층(layer)마다 적용이 됩니다.\n",
    "\n",
    "사실 케라스로 인공 신경망을 만들면 이러한 연산 과정을 자세히 이해하지 않아도 모델을 만들 수는 있지만, Numpy 등을 통해 인공 신경망을 로우 레벨로 개발하고 있다면 인공 신경망 내부 연산에 사용하는 행렬 크기를 고려해야 인공 신경망을 구현할 수 있습니다. 그렇기 때문에 비록 이 책은 케라스를 사용하지만, 적어도 로우 레벨 단계에서는 행렬의 크기가 어떻게 결정되는지 이해해보고자 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) layer 1의 행렬 크기 추정하기**\n",
    "\n",
    "우선 각 층을 기준으로 입력과 출력의 개수를 정리하면 다음과 같습니다.\n",
    "\n",
    "- **입력층 (layer 0) :** 4개의 입력과 8개의 출력\n",
    "- **은닉층1 (layer 1) :** 8개의 입력과 8개의 출력\n",
    "- **은닉층2 (layer 2) :** 8개의 입력과 3개의 출력\n",
    "- **출력층 (layer 3) :** 3개의 입력과 3개의 출력\n",
    "\n",
    "여기서는 편의상 입력층을 layer 0, 은닉층 1을 layer 1, 은닉층 2를 layer 2, 출력층을 layer 3라고 해봅시다. 이제 위의 정보를 가지고 층마다 생기는 가중치와 편향 행렬의 크기를 추정해봅시다. 벡터와 행렬 연산 챕터에서 언급하였듯이 가중치 행렬에 입력 행렬을 곱하는 경우와 입력 행렬에 가중치 행렬을 곱하는 경우가 있겠으나, 여기서는 후자를 가정합니다. 또한 배치 크기는 1로 합니다.\n",
    "\n",
    "이 경우 layer 1에서 처음 입력으로 들어오는 입력 행렬 $X$의 크기는 1 × 4로 행벡터에 해당됩니다. (만약 미니 배치 학습을 가정할 경우, $X$의 크기는 배치의 크기 × 4가 됩니다.)\n",
    "\n",
    "앞서 벡터와 행렬 연산 챕터에서 배운 바에 따르면, 입력 행렬, 가중치 행렬, 편향 행렬, 출력 행렬은 다음과 같은 크기 관계를 가집니다.\n",
    "<br>\n",
    "$$\n",
    "X_{m\\ \\text{×}\\ n} × W_{n\\ \\text{×}\\ j} + B_{m\\ \\text{×}\\ j} = Y_{m\\ \\text{×}\\ j}\n",
    "$$\n",
    "<br>\n",
    "layer 1의 입력 행렬 X 의 크기는 1 × 4입니다. layer 1의 출력은 8개이므로, 그에 따라 출력 행렬 Y의 크기는 1 × 8이 됩니다.\n",
    "<br>\n",
    "$$\n",
    "X_{1\\ \\text{×}\\ 4} × W_{n\\ \\text{×}\\ j} + B_{m\\ \\text{×}\\ j} = Y_{1\\ \\text{×}\\ 8}\n",
    "$$\n",
    "그런데 가중치 행렬 $W$의 행은 입력 행렬 $X$의 열과 같아야 하므로 아래와 같습니다. <br>\n",
    "$$\n",
    "X_{1\\ \\text{×}\\ 4} × W_{4\\ \\text{×}\\ j} + B_{m\\ \\text{×}\\ j} = Y_{1\\ \\text{×}\\ 8}\n",
    "$$\n",
    "<br>\n",
    "편향 행렬 $B$는 출력 행렬 $Y$의 크기에 영향을 주지 않으므로 편향 행렬 $B$의 크기는 출력 행렬 $Y$의 크기와 같습니다.\n",
    "<br>\n",
    "$$\n",
    "X_{1\\ \\text{×}\\ 4} × W_{4\\ \\text{×}\\ j} + B_{1\\ \\text{×}\\ 8} = Y_{1\\ \\text{×}\\ 8}\n",
    "$$\n",
    "<br>\n",
    "가중치 행렬 $W$의 열은 출력 행렬 $Y$의 열과 동일해야 합니다.\n",
    "<br>\n",
    "$$\n",
    "X_{1\\ \\text{×}\\ 4} × W_{4\\ \\text{×}\\ 8} + B_{1\\ \\text{×}\\ 8} = Y_{1\\ \\text{×}\\ 8}\n",
    "$$\n",
    "<br>\n",
    "layer 1의 가중치 행렬과 편향 행렬의 크기를 구했습니다. 이제 layer 1의 출력 행렬 $Y$는 layer 2에서는 입력 행렬 $X$가 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) layer 2와 layer 3의 행렬 크기 추정하기**\n",
    "\n",
    "이를 반복하면 layer 2와 layer 3에서의 가중치 행렬과 편향 행렬의 크기를 구할 수 있습니다. 비록 은닉층과 출력층에 활성화 함수가 존재하지만 활성화 함수는 행렬의 크기에 영향을 주지 않습니다.\n",
    "\n",
    "- layer 2 : $X_{1\\ \\text{×}\\ 8} × W_{8\\ \\text{×}\\ 8} + B_{1\\ \\text{×}\\ 8} = Y_{1\\ \\text{×}\\ 8}$\n",
    "- layer 3 : $X_{1\\ \\text{×}\\ 8} × W_{8\\ \\text{×}\\ 3} + B_{1\\ \\text{×}\\ 3} = Y_{1\\ \\text{×}\\ 3}$\n",
    "\n",
    "인공 신경망이 입력층에서 은닉층을 지나 출력층에서 예측값을 계산하기까지의 과정을 행렬 연산으로 가정하고 행렬의 크기를 추정해보았습니다. 이와 같이 순전파를 진행하고 예측값을 구하고나서 이 다음에 인공 신경망이 해야할 일은 예측값과 실제값으로부터 오차를 계산하고, 오차로부터 가중치와 편향을 업데이트하는 일입니다. 즉, 인공 신경망의 학습 단계에 해당됩니다. 이때 인공 신경망은 순전파와는 반대 방향으로 연산을 진행하며 가중치를 업데이트하는데, 이 과정을 역전파(BackPropagation)라고 합니다. 인공 신경망의 이러한 학습 방법에 대해서는 다음 챕터에서 배웁니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### #추천 참고 자료 : https://www.youtube.com/watch?v=UJwK6jAStmg\n",
    "위의 짧은 영상은 행렬을 통한 인공 신경망의 순전파 과정을 영상을 통해 보여줍니다. 이번 설명에서 배치 크기를 1로 가정하였지만, 위의 영상에서는 3개의 데이터를 한 꺼번에 연산합니다. 입력 행렬 X의 행이 3이 되는 것이죠. 하지만 행렬의 크기가 결정되는 원리는 달라지지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# **딥 러닝의 학습 방법**\n",
    "이번 챕터에서는 머신 러닝 챕터에서 배운 손실 함수와 옵티마이저의 개념을 가지고, 딥 러닝에서 어떻게 학습을 하는지에 대해서 배웁니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. 순전파(Foward Propagation)**\n",
    "\n",
    "![img](https://wikidocs.net/images/page/36033/%EC%88%9C%EC%A0%84%ED%8C%8C.PNG)\n",
    "\n",
    "활성화 함수, 은닉층의 수, 각 은닉층의 뉴런 수 등 딥 러닝 모델을 설계하고나면 입력값은 입력층, 은닉층을 지나면서 각 층에서의 가중치와 함께 연산되며 출력층으로 향합니다. 그리고 출력층에서 모든 연산을 마친 예측값이 나오게 됩니다. 이와 같이 ***입력층에서 출력층 방향으로 예측값의 연산이 진행되는 과정을 순전파라고 합니다.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **2. 손실 함수(Loss function)**\n",
    "\n",
    "![img](https://wikidocs.net/images/page/36033/%EC%86%90%EC%8B%A4%ED%95%A8%EC%88%98.PNG)\n",
    "\n",
    "***손실 함수는 실제값과 예측값의 차이를 수치화해주는 함수***입니다. 이 두 값의 차이. 즉, 오차가 클 수록 손실 함수의 값은 크고 오차가 작을 수록 손실 함수의 값은 작아집니다. 회귀에서는 평균 제곱 오차, 분류 문제에서는 크로스 엔트로피를 주로 손실 함수로 사용합니다. 손실 함수의 값을 최소화하는 두 개의 매개변수인 가중치 W와 편향 b를 찾아가는 것이딥 러닝의 학습 과정이므로 손실 함수의 선정은 매우 중요합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) MSE(Mean Squared Error, MSE)**\n",
    "\n",
    "오차 제곱 평균을 의미합니다. 연속형 변수를 예측할 때 사용됩니다.\n",
    "![img](https://wikidocs.net/images/page/24987/mse.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) 크로스 엔트로피(Cross-Entropy)**\n",
    "\n",
    "y : 실제값 (0 or 1) / y^ : 예측값 (확률)\n",
    "![img](https://wikidocs.net/images/page/24987/%ED%81%AC%EB%A1%9C%EC%8A%A4%EC%97%94%ED%8A%B8%EB%A1%9C%ED%94%BC.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "낮은 확률로 예측해서 맞추거나, 높은 확률로 예측해서 틀리는 경우 loss가 더 큽니다. \n",
    "\n",
    "- **이진 분류 (Binary Classification)**의 경우 binary_crossentropy를 사용하며\n",
    "- **다중 클래스 분류(Multi-Class Classification)**일 경우 categorical_crossentropy를 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **3. 옵티마이저(Optimizer)**\n",
    "\n",
    "![img](https://wikidocs.net/images/page/36033/%EC%97%AD%EC%A0%84%ED%8C%8C_%EA%B3%BC%EC%A0%95.PNG)\n",
    "\n",
    "손실 함수의 값을 줄여나가면서 학습하는 방법은 어떤 옵티마이저를 사용하느냐에 따라 달라집니다. 여기서 **배치(Batch)**라는 개념에 대한 이해가 필요합니다. ***배치는 가중치 등의 매개 변수의 값을 조정하기 위해 사용하는 데이터의 양을 말합니다.*** 전체 데이터를 가지고 매개 변수의 값을 조정할 수도 있고, 정해준 양의 데이터만 가지고도 매개 변수의 값을 조정할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) 배치 경사 하강법(Batch Gradient Descent)**\n",
    "\n",
    "배치 경사 하강법(Batch Gradient Descent)은 가장 기본적인 경사 하강법입니다. 배치 경사 하강법은 ***옵티마이저 중 하나로 오차(loss)를 구할 때 전체 데이터를 고려***합니다. 머신 러닝에서는 1번의 훈련 횟수를 1 에포크라고 하는데, 배치 경사 하강법은 한 번의 에포크에 모든 매개변수 업데이트를 단 한 번 수행합니다. 배치 경사 하강법은\n",
    "\n",
    "- 전체 데이터를 고려해서 학습하므로 ***에포크당 시간이 오래 걸리며, 메모리를 크게 요구한다는 단점***이 있으나\n",
    "- ***글로벌 미니멈을 찾을 수 있다는 장점***이 있습니다.\n",
    "\n",
    "```python\n",
    "model.fit(X_train, y_train, batch_size=len(trainX))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) 확률적 경사 하강법(Stochastic Gradient Descent, SGD)**\n",
    "\n",
    "기존의 배치 경사 하강법은 전체 데이터에 대해서 계산을 하다보니 시간이 너무 오래걸린다는 단점이 있습니다. 확률적 경사 하강법은 매개변수 값을 조정 시 전체 데이터가 아니라 랜덤으로 선택한 하나의 데이터에 대해서만 계산하는 방법입니다. 더 적은 데이터를 사용하므로 더 빠르게 계산할 수 있습니다.\n",
    "\n",
    "![img](https://wikidocs.net/images/page/24987/%EA%B2%BD%EC%82%AC%ED%95%98%EA%B0%95%EB%B2%95SGD.PNG)\n",
    "\n",
    "매개변수의 변경폭이 불안정하고, 때로는 배치 경사 하강법보다 정확도가 낮을 수도 있지만 속도만큼은 배치 경사 하강법보다 빠르다는 장점이 있습니다. 케라스에서는 아래와 같이 사용합니다.\n",
    "\n",
    "```python\n",
    "model.fit(X_train, y_train, batch_size=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3) 미니 배치 경사 하강법(Mini-Batch Gradient Descent)**\n",
    "\n",
    "전체 데이터도 아니고, 1개의 데이터도 아니고 ***정해진 양에 대해서만 계산하여 매개 변수의 값을 조정하는 경사 하강법***을 미니 배치 경사 하강법이라고 합니다. 미니 배치 경사 하강법은 전체 데이터를 계산하는 것보다 빠르며, ***SGD보다 안정적이라는 장점***이 있습니다. 실제로 ***가장 많이 사용되는 경사 하강법***입니다.\n",
    "\n",
    "```python\n",
    "model.fit(X_train, y_train, batch_size=32) #32를 배치 크기로 하였을 경우\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4) 모멘텀(Momentum)**\n",
    "\n",
    "모멘텀(Momentum)은 관성이라는 물리학의 법칙을 응용한 방법입니다. 모멘텀 SGD는 경사 하강법에 관성을 더 해줍니다. 모멘텀은 SGD에서 계산된 접선의 기울기에 한 시점(step) 전의 접선의 기울기값을 일정한 비율만큼 반영합니다. 이렇게 하면 마치 언덕에서 공이 내려올 때, 중간에 작은 웅덩이에 빠지더라도 관성의 힘으로 넘어서는 효과를 줄 수 있습니다.\n",
    "\n",
    "![img](https://wikidocs.net/images/page/24987/%EB%A1%9C%EC%BB%AC%EB%AF%B8%EB%8B%88%EB%A9%88.PNG)\n",
    "\n",
    "다시 말해 로컬 미니멈에 도달하였을 때, 기울기가 0이라서 기존의 경사 하강법이라면 이를 글로벌 미니멈으로 잘못 인식하여 계산이 끝났을 상황이라도 모멘텀. 즉, 관성의 힘을 빌리면 값이 조절되면서 로컬 미니멈에서 탈출하는 효과를 얻을 수도 있습니다. 케라스에서는 다음과 같이 사용합니다.\n",
    "\n",
    "```python\n",
    "keras.optimizers.SGD(lr = 0.01, momentum= 0.9)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5) 아다그라드(Adagrad)**\n",
    "\n",
    "매개변수들은 각자 의미하는 바가 다른데, 모든 매개변수에 동일한 학습률(learning rate)을 적용하는 것은 비효율적입니다. 아다그라드는 각 매개변수에 서로 다른 학습률을 적용시킵니다. 이 때, 변화가 많은 매개변수는 학습률이 작게 설정되고 변화가 적은 매개변수는 학습률을 높게 설정시킵니다. 케라스에서는 다음과 같이 사용합니다.\n",
    "\n",
    "```python\n",
    "keras.optimizers.Adagrad(lr=0.01, epsilon=1e-6)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6) 알엠에스프롭(RMSprop)**\n",
    "\n",
    "아다그라드는 학습을 계속 진행한 경우에는, 나중에 가서는 학습률이 지나치게 떨어진다는 단점이 있는데 이를 다른 수식으로 대체하여 이러한 단점을 개선하였습니다. 케라스에서는 다음과 같이 사용합니다.\n",
    "\n",
    "```python\n",
    "keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-06)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7) 아담(Adam)**\n",
    "\n",
    "아담은 알엠에스프롭과 모멘텀 두 가지를 합친 듯한 방법으로, 방향과 학습률 두 가지를 모두 잡기 위한 방법입니다. 케라스에서는 다음과 같이 사용합니다.\n",
    "\n",
    "```python\n",
    "keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "```\n",
    "\n",
    "*케라스의 옵티마이저 사용법은 아래의 링크에서 좀 더 상세히 확인할 수 있습니다.*\n",
    "*링크 : https://keras.io/optimizers/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **4. 에포크와 배치 크기와 이터레이션(Epochs and Batch size and Iteration)**\n",
    "\n",
    "기계는 실제값과 예측값의 오차로부터 옵티마이저를 통해서 가중치를 업데이트합니다. 머신 러닝에서는 이 과정을 **학습**이라고 합니다. 이를 현실의 학습에 비유하면 사람은 문제지의 문제를 풀고, 정답지의 정답을 보면서 채점을 하면서 부족했던 점을 깨달으며 머릿속의 지식이 업데이트되는 과정입니다.\n",
    "\n",
    "그런데 사람마다 동일한 문제지와 정답지를 주더라도 공부 방법은 사실 천차만별입니다. 어떤 사람은 문제지 하나를 다 풀고 나서 정답을 채점하는데 어떤 사람은 문제지의 문제를 10개 단위로 끊어서 공부합니다. 문제 10개를 풀고 채점하고 다시 다음 문제 10개를 풀고 채점하고 반복하는 방식으로 학습한다는 거죠. 또한 게으른 사람은 문제지를 3번 공부하는데, 성실한 사람은 문제지의 문제를 달달 외울만큼 문제지를 100번 공부합니다.\n",
    "\n",
    "기계도 똑같습니다. 같은 문제지와 정답지를 주더라도 공부 방법을 다르게 설정할 수 있습니다.\n",
    "\n",
    "![img](https://wikidocs.net/images/page/36033/batchandepochiteration.PNG)\n",
    "\n",
    "위의 그림은 에포크와 배치 크기와 이터레이션의 차이를 보여줍니다. 위의 그림의 예제를 통해 설명해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) 에포크(Epoch)**\n",
    "\n",
    "에포크란 인공 신경망에서 ***전체 데이터에 대해서 순전파와 역전파가 끝난 상태***를 말합니다. 전체 데이터를 하나의 문제지에 비유한다면 문제지의 모든 문제를 끝까지 다 풀고, 정답지로 채점을 하여 문제지에 대한 공부를 한 번 끝낸 상태를 말합니다.\n",
    "\n",
    "***만약 에포크가 50이라고 하면, 전체 데이터 단위로는 총 50번 학습합니다.*** 문제지에 비유하면 문제지를 50번 푼 셈입니다. 이 에포크 횟수가 지나치거나 너무 적으면 앞서 배운 과적합과 과소적합이 발생할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) 배치 크기(Batch size)**\n",
    "\n",
    "배치 크기는 몇 개의 데이터 단위로 매개변수를 업데이트 하는지를 말합니다. 현실에 비유하면 문제지에서 몇 개씩 문제를 풀고나서 정답지를 확인하느냐의 문제입니다. 사람은 문제를 풀고 정답을 보는 순간 부족했던 점을 깨달으며 지식이 업데이트 된다고 하였습니다. 기계 입장에서는 실제값과 예측값으로부터 오차를 계산하고 옵티마이저가 매개변수를 업데이트합니다. 여기서 중요한 포인트는 업데이트가 시작되는 시점이 정답지/실제값을 확인하는 시점이라는 겁니다.\n",
    "\n",
    "- 사람이 **2,000 문제가 수록되어있는 문제지의 문제를 200개 단위로 풀고 채점**한다고 하면 이때 **배치 크기는 200**입니다.\n",
    "- 기계는 **배치 크기가 200이면 200개의 샘플 단위로 가중치를 업데이트** 합니다.\n",
    "\n",
    "여기서 주의할 점은 **배치 크기와 배치의 수는 다른 개념이라는 점**입니다. 전체 데이터가 2,000일때 배치 크기를 200으로 준다면 배치의 수는 10입니다. 이는 에포크에서 배치 크기를 나눠준 값(2,000/200 = 10)이기도 합니다. 이때 배치의 수를 이터레이션이라고 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3) 이터레이션(Iteration)**\n",
    "\n",
    "이터레이션이란 **한 번의 에포크를 끝내기 위해서 필요한 배치의 수**를 말합니다. 또는 **한 번의 에포크 내에서 이루어지는 매개변수의 업데이트 횟수**이기도 합니다.\n",
    "\n",
    "- 전체 데이터가 2,000일 때 배치 크기를 200으로 한다면 이터레이션의 수는 총 10개입니다.\n",
    "- 이는 한 번의 에포크 당 매개변수 업데이트가 10번 이루어진다는 것을 의미합니다.\n",
    "\n",
    "SGD를 이 개념을 가지고 다시 설명하면, SGD는 배치 크기가 1이므로 모든 이터레이션마다 하나의 데이터를 선택하여 경사 하강법을 수행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **5. 과적합을 막는 방법**\n",
    "\n",
    "과적합은 ***주로 훈련 데이터의 양이 적거나,*** 매개변수가 많은 모델에서 주로 일어나며 과하게 훈련되어 ***훈련 데이터에 대해서는 정확도가 높지만 그 외의 데이터에 대해서는 정확도가 낮은 상태***를 말합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) 조기 종료(Early Stopping)**\n",
    "\n",
    "과적합을 막는 방법 중 하나는 훈련을 조기 종료 하는 것입니다. 조기 종료의 방법은 간단합니다. 훈련 데이터뿐만 아니라, 검증 데이터에 대해서도 정확도에 대한 모니터링을 진행하면서 검증 데이터에 대한 정확도가 꾸준히 낮아지는 순간이 발견된다면, ***정확도가 낮아지기 전의 가장 정확도가 높은 순간을 가장 적절한 훈련 에포크로 잡으면 됩니다.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) 드롭아웃(DropOut)**\n",
    "\n",
    "인공 신경망 학습 중에 어떤 확률 p(하이퍼파라미터)를 기준으로 선택된 노드들을 학습에 사용하지 않도록 합니다. 즉, ***임의의 확률로 일부 뉴런들을 비활성화 시킵니다.*** 이는 인공 신경망이 특정 뉴런이나 특정 뉴런들의 조합에 너무 의존적으로 변하는 것을 방지합니다. 이 작업은 매 학습마다 무작위로 뉴런들을 선택해서 학습에서 제외시키는데 이렇게 하면 다양한 조합으로 학습이 되는 효과가 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# **역전파(BackPropagation) 이해하기**\n",
    "인공 신경망이 순전파 과정을 진행하여 예측값과 실제값의 오차를 계산하였을 때 어떻게 역전파 과정에서 경사 하강법을 사용하여 가중치를 업데이트하는지 직접 계산을 통해 이해해봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. 인공 신경망의 이해(Neural Network Overview)**\n",
    "\n",
    "우선 예제를 위해 사용될 인공 신경망을 소개합니다. 역전파의 이해를 위해서 여기서 사용할 인공 신경망은 입력층, 은닉층, 출력층 이렇게 3개의 층을 가집니다. 또한 해당 인공 신경망은 두 개의 입력과, 두 개의 은닉층 뉴런, 두 개의 출력층 뉴런을 사용합니다. 은닉층과 출력층의 모든 뉴런은 활성화 함수로 시그모이드 함수를 사용합니다.\n",
    "\n",
    "![img](https://wikidocs.net/images/page/37406/nn1_final.PNG)\n",
    "\n",
    "위의 그림은 여기서 사용할 인공 신경망의 모습을 보여줍니다. 은닉층과 출력층의 모든 뉴런에서 변수 $z$가 존재하는데 여기서 변수 $z$는 이전층의 모든 입력이 각각의 가중치와 곱해진 값들이 모두 더해진 가중합을 의미합니다. 이 값은 뉴런에서 아직 시그모이드 함수를 거치지 않은 상태입니다. 즉, 활성화 함수의 입력을 의미합니다. $z$ 우측의 |를 지나서 존재하는 변수 $h$ 또는 $o$는 $z$가 시그모이드 함수를 지난 후의 값으로 각 뉴런의 출력값을 의미합니다. 이번 역전파 예제에서는 인공 신경망에 존재하는 모든 가중치 $W$에 대해서 역전파를 통해 업데이트하는 것을 목표로합니다. 해당 인공 신경망은 편향 $b$는 고려하지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **2. 순전파(Forward Propagation)**\n",
    "\n",
    "![img](https://wikidocs.net/images/page/37406/nn2_final_final.PNG)\n",
    "\n",
    "주어진 값이 위의 그림과 같을 때 순전파를 진행해봅시다. 위의 그림에서 소수점 앞의 0은 생략하였습니다. 예를 들어 .25는 0.25를 의미합니다. 파란색 숫자는 입력값을 의미하며, 빨간색 숫자는 각 가중치의 값을 의미합니다. 앞으로 진행하는 계산의 결과값은 소수점 아래 여덟번째 자리까지 반올림하여 표기합니다.\n",
    "\n",
    "각 입력은 입력층에서 은닉층 방향으로 향하면서 각 입력에 해당하는 가중치와 곱해지고, 결과적으로 가중합으로 계산되어 은닉층 뉴런의 시그모이드 함수의 입력값이 됩니다. $z_{1}$과 $z_{2}$는 시그모이드 함수의 입력으로 사용되는 각각의 값에 해당됩니다.\n",
    "\n",
    "<br>\n",
    "$$\n",
    "z_{1}=W_{1}x_{1} + W_{2}x_{2}=0.3 \\text{×} 0.1 + 0.25 \\text{×} 0.2= 0.08\n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "z_{2}=W_{3}x_{1} + W_{4}x_{2}=0.4 \\text{×} 0.1 + 0.35 \\text{×} 0.2= 0.11\n",
    "$$\n",
    "<br>\n",
    "\n",
    "$z_{1}$과 $z_{2}$는 각각의 은닉층 뉴런에서 시그모이드 함수를 지나게 되는데 시그모이드 함수가 리턴하는 결과값은 은닉층 뉴런의 최종 출력값입니다. 식에서는 각각 $h_{1}$과 $h_{2}$에 해당되며, 아래의 결과와 같습니다.\n",
    "\n",
    "<br>\n",
    "$$\n",
    "h_{1}=sigmoid(z_{1}) = 0.51998934\n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "h_{2}=sigmoid(z_{2}) = 0.52747230\n",
    "$$\n",
    "<br>\n",
    "\n",
    "$h_{1}$과 $h_{2}$ 이 두 값은 다시 출력층의 뉴런으로 향하게 되는데 이때 다시 각각의 값에 해당되는 가중치와 곱해지고, 다시 가중합 되어 출력층 뉴런의 시그모이드 함수의 입력값이 됩니다. 식에서는 각각 $z_{3}$과 $z_{4}에 해당됩니다.\n",
    "\n",
    "<br>\n",
    "$$\n",
    "z_{3}=W_{5}h_{1}+W_{6}h_{2} = 0.45 \\text{×} h_{1} + 0.4 \\text{×} h_{2} = 0.44498412\n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "z_{4}=W_{7}h_{1}+W_{8}h_{2} = 0.7 \\text{×} h_{1} + 0.6 \\text{×} h_{2} = 0.68047592\n",
    "$$\n",
    "<br>\n",
    "\n",
    "$z_{3}$과 $z_{4}이 출력층 뉴런에서 시그모이드 함수를 지난 값은 이 인공 신경망이 최종적으로 계산한 출력값입니다. 실제값을 예측하기 위한 값으로서 예측값이라고도 부릅니다.\n",
    "\n",
    "<br>\n",
    "$$\n",
    "o_{1}=sigmoid(z_{3})=0.60944600\n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "o_{2}=sigmoid(z_{4})=0.66384491\n",
    "$$\n",
    "<br>\n",
    "\n",
    "이제 해야할 일은 예측값과 실제값의 오차를 계산하기 위한 오차 함수를 선택하는 것입니다. 오차(Error)를 계산하기 위한 손실 함수(Loss function)로는 평균 제곱 오차 MSE를 사용합니다. 식에서는 실제값을 target이라고 표현하였으며, 순전파를 통해 나온 예측값을 output으로 표현하였습니다. 그리고 각 오차를 모두 더하면 전체 오차 $E_{total}$가 됩니다.\n",
    "\n",
    "<br>\n",
    "$$\n",
    "E_{o1}=\\frac{1}{2}(target_{o1}-output_{o1})^{2}=0.02193381\n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "E_{o2}=\\frac{1}{2}(target_{o2}-output_{o2})^{2}=0.00203809\n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "E_{total}=E_{o1}+E_{o2}=0.02397190\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **3. 역전파 1단계(BackPropagation Step 1)**\n",
    "\n",
    "순전파가 입력층에서 출력층으로 향한다면 역전파는 반대로 출력층에서 입력층 방향으로 계산하면서 가중치를 업데이트해갑니다. 출력층 바로 이전의 은닉층을 N층이라고 하였을 때, 출력층과 N층 사이의 가중치를 업데이트하는 단계를 역전파 1단계, 그리고 N층과 N층의 이전층 사이의 가중치를 업데이트 하는 단계를 역전파 2단계라고 해봅시다.\n",
    "\n",
    "![img](https://wikidocs.net/images/page/37406/nn3_final.PNG)\n",
    "\n",
    "역전파 1단계에서 업데이트 해야 할 가중치는 $W_{5}, W_{6}, W_{7}, W_{8}$ 총 4개입니다. 원리 자체는 동일하므로 우선 $W_{5}$에 대해서 먼저 업데이트를 진행해보겠습니다. 경사 하강법을 수행하려면 가중치 $W_{5}$를 업데이트 하기 위해서 $\\frac{∂E_{total}}{∂W_{5}}$를 계산해야 합니다.\n",
    "\n",
    "$\\frac{∂E_{total}}{∂W_{5}}$를 계산하기 위해 미분의 연쇄 법칙(Chain rule)에 따라서 이와 같이 풀어 쓸 수 있습니다. \n",
    "\n",
    "<br>\n",
    "$$\n",
    "\\frac{∂E_{total}}{∂W_{5}} = \\frac{∂E_{total}}{∂o_{1}} \\text{×} \\frac{∂o_{1}}{∂z_{3}} \\text{×} \\frac{∂z_{3}}{∂W_{5}}\n",
    "$$\n",
    "<br>\n",
    "\n",
    "위의 식에서 우변의 세 개의 각 항에 대해서 순서대로 계산해봅시다. 우선 첫번째 항에 대해서 계산해보겠습니다. 미분을 진행하기 전에 $E_{total}$의 값을 상기해봅시다. $E_{total}$은 앞서 순전파를 진행하고 계산했던 전체 오차값입니다. 식은 다음과 같습니다.\n",
    "\n",
    "<br>\n",
    "$$\n",
    "E_{total}=\\frac{1}{2}(target_{o1}-output_{o1})^{2} + \\frac{1}{2}(target_{o2}-output_{o2})^{2}\n",
    "$$\n",
    "<br>\n",
    "\n",
    "이에 $\\frac{∂E_{total}}{∂o_{1}}$는 다음과 같습니다.\n",
    "\n",
    "<br>\n",
    "$$\n",
    "\\frac{∂E_{total}}{∂o_{1}}=2 \\text{×} \\frac{1}{2}(target_{o1}-output_{o1})^{2-1} \\text{×} (-1) + 0\n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "\\frac{∂E_{total}}{∂o_{1}}=-(target_{o1}-output_{o1})=-(0.4-0.60944600)=0.20944600\n",
    "$$\n",
    "<br>\n",
    "\n",
    "이제 두번째 항을 주목해봅시다. $o_{1}$이라는 값은 시그모이드 함수의 출력값입니다. 그런데 시그모이드 함수의 미분은 $f(x) \\text{×} (1-f(x))$입니다. 앞으로의 계산 과정에서도 계속해서 시그모이드 함수를 미분해야 하는 상황이 생기므로 기억해둡시다. 이에 따라서 두번째 항의 미분 결과는 다음과 같습니다.\n",
    "\n",
    "<br>\n",
    "$$\n",
    "\\frac{∂o_{1}}{∂z_{3}}=o_{1}\\text{×}(1-o_{1})=0.60944600(1-0.60944600)=0.23802157\n",
    "$$\n",
    "<br>\n",
    "\n",
    "마지막으로 세번째 항은 $h_{1}$의 값과 동일합니다.\n",
    "\n",
    "<br>\n",
    "$$\n",
    "\\frac{∂z_{3}}{∂W_{5}}=h_{1}=0.51998934\n",
    "$$\n",
    "<br>\n",
    "\n",
    "우변의 모든 항을 계산하였습니다. 이제 이 값을 모두 곱해주면 됩니다.\n",
    "\n",
    "<br>\n",
    "$$\n",
    "\\frac{∂E_{total}}{∂W_{5}} = 0.20944600 \\text{×} 0.23802157 \\text{×} 0.51998934 = 0.02592286\n",
    "$$\n",
    "<br>\n",
    "\n",
    "이제 앞서 배웠던 경사 하강법을 통해 가중치를 업데이트 할 때가 왔습니다! 하이퍼파라미터에 해당되는 학습률(learning rate) $α$는 0.5라고 가정합니다.\n",
    "\n",
    "<br>\n",
    "$$\n",
    "W_{5}^{+}=W_{5}-α\\frac{∂E_{total}}{∂W_{5}}=0.45- 0.5 \\text{×} 0.02592286=0.43703857\n",
    "$$\n",
    "<br>\n",
    "\n",
    "이와 같은 원리로 $W_{6}^{+},\\ W_{7}^{+},\\ W_{8}^{+}$을 계산할 수 있습니다.\n",
    "\n",
    "<br>\n",
    "$$\n",
    "\\frac{∂E_{total}}{∂W_{6}} = \\frac{∂E_{total}}{∂o_{1}} \\text{×} \\frac{∂o_{1}}{∂z_{3}} \\text{×} \\frac{∂z_{3}}{∂W_{6}} → W_{6}^{+}=0.38685205\n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "\\frac{∂E_{total}}{∂W_{7}} = \\frac{∂E_{total}}{∂o_{2}} \\text{×} \\frac{∂o_{2}}{∂z_{4}} \\text{×} \\frac{∂z_{4}}{∂W_{7}} → W_{7}^{+}=0.69629578\n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "\\frac{∂E_{total}}{∂W_{8}} = \\frac{∂E_{total}}{∂o_{2}} \\text{×} \\frac{∂o_{2}}{∂z_{4}} \\text{×} \\frac{∂z_{4}}{∂W_{8}} → W_{8}^{+}=0.59624247\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **4. 역전파 2단계(BackPropagation Step 2)**\n",
    "\n",
    "![img](https://wikidocs.net/images/page/37406/nn4.PNG)\n",
    "\n",
    "1단계를 완료하였다면 이제 입력층 방향으로 이동하며 다시 계산을 이어갑니다. 위의 그림에서 빨간색 화살표는 순전파의 정반대 방향인 역전파의 방향을 보여줍니다. 현재 인공 신경망은 은닉층이 1개밖에 없으므로 이번 단계가 마지막 단계입니다. 하지만 은닉층이 더 많은 경우라면 입력층 방향으로 한 단계씩 계속해서 계산해가야 합니다.\n",
    "\n",
    "이번 단계에서 계산할 가중치는 $W_{1}, W_{2}, W_{3}, W_{4}$입니다. 원리 자체는 동일하므로 우선 $W_{1}$에 대해서 먼저 업데이트를 진행해보겠습니다. 경사 하강법을 수행하려면 가중치 $W_{1}$를 업데이트 하기 위해서 $\\frac{∂E_{total}}{∂W_{1}}$를 계산해야 합니다.\n",
    "\n",
    "$\\frac{∂E_{total}}{∂W_{1}}$를 계산하기 위해 미분의 연쇄 법칙(Chain rule)에 따라서 이와 같이 풀어 쓸 수 있습니다.\n",
    "\n",
    "<br>\n",
    "$$\n",
    "\\frac{∂E_{total}}{∂W_{1}} = \\frac{∂E_{total}}{∂h_{1}} \\text{×} \\frac{∂h_{1}}{∂z_{1}} \\text{×} \\frac{∂z_{1}}{∂W_{1}}\n",
    "$$\n",
    "<br>\n",
    "\n",
    "위의 식에서 우변의 첫번째항인 $\\frac{∂E_{total}}{∂h_{1}}$는 다음과 같이 다시 식을 풀어서 쓸 수 있습니다.\n",
    "\n",
    "<br>\n",
    "$$\n",
    "\\frac{∂E_{total}}{∂h_{1}} = \\frac{∂E_{o1}}{∂h_{1}} + \\frac{∂E_{o2}}{∂h_{1}}\n",
    "$$\n",
    "<br>\n",
    "\n",
    "위의 식의 우변의 두 항을 각각 구해봅시다. 우선 첫번째 항 $\\frac{∂E_{o1}}{∂h_{1}}$에 대해서 항을 분해 및 계산해보겠습니다.\n",
    "\n",
    "<br>\n",
    "$$\n",
    "\\frac{∂E_{o1}}{∂h_{1}} = \\frac{∂E_{o1}}{∂z_{3}} \\text{×} \\frac{{∂z_{3}}}{∂h_{1}} = \\frac{∂E_{o1}}{∂o_{1}} \\text{×} \\frac{∂o_{1}}{∂z_{3}} \\text{×} \\frac{{∂z_{3}}}{∂h_{1}}\n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "= -(target_{o1}-output_{o1}) \\text{×} o_{1}\\text{×}(1-o_{1}) \\text{×} W_{5}\n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "= 0.20944600 \\text{×} 0.23802157 \\text{×} 0.45 = 0.02243370\n",
    "$$\n",
    "<br>\n",
    "\n",
    "이와 같은 원리로 $\\frac{∂E_{o2}}{∂h_{1}}$ 또한 구합니다.\n",
    "\n",
    "<br>\n",
    "$$\n",
    "\\frac{∂E_{o2}}{∂h_{1}} = \\frac{∂E_{o2}}{∂z_{4}} \\text{×} \\frac{{∂z_{4}}}{∂h_{1}} = \\frac{∂E_{o2}}{∂o_{2}} \\text{×} \\frac{∂o_{2}}{∂z_{4}} \\text{×} \\frac{{∂z_{4}}}{∂h_{1}} = 0.00997311\n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "\\frac{∂E_{total}}{∂h_{1}} = 0.02243370 + 0.00997311 = 0.03240681\n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "\\frac{∂E_{total}}{∂h_{1}} = 0.02243370 + 0.00997311 = 0.03240681\n",
    "$$\n",
    "<br>\n",
    "\n",
    "이제 $\\frac{∂E_{total}}{∂W_{1}}$를 구하기 위해서 필요한 첫번째 항을 구했습니다. 나머지 두 항에 대해서 구해보도록 하겠습니다.\n",
    "\n",
    "<br>\n",
    "$$\n",
    "\\frac{∂h_{1}}{∂z_{1}} = h_{1}\\text{×}(1-h_{1}) = 0.51998934(1-0.51998934)=0.24960043\n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "\\frac{∂z_{1}}{∂W_{1}} = x_{1} = 0.1\n",
    "$$\n",
    "<br>\n",
    "\n",
    "즉, $\\frac{∂E_{total}}{∂W_{1}}$는 다음과 같습니다.\n",
    "\n",
    "<br>\n",
    "$$\n",
    "\\frac{∂E_{total}}{∂W_{1}} = 0.03240681 \\text{×} 0.24960043 \\text{×} 0.1 = 0.00080888\n",
    "$$\n",
    "<br>\n",
    "\n",
    "이제 앞서 배웠던 경사 하강법을 통해 가중치를 업데이트 할 수 있습니다.\n",
    "\n",
    "<br>\n",
    "$$\n",
    "W_{1}^{+}=W_{1}-α\\frac{∂E_{total}}{∂W_{1}}=0.1- 0.5 \\text{×} 0.00080888=0.29959556\n",
    "$$\n",
    "<br>\n",
    "\n",
    "이와 같은 원리로 $W_{2}^{+},\\ W_{3}^{+},\\ W_{4}^{+}$을 계산할 수 있습니다.\n",
    "\n",
    "<br>\n",
    "$$\n",
    "\\frac{∂E_{total}}{∂W_{2}} = \\frac{∂E_{total}}{∂h_{1}} \\text{×} \\frac{∂h_{1}}{∂z_{1}} \\text{×} \\frac{∂z_{1}}{∂W_{2}}  → W_{2}^{+}=0.24919112\n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "\\frac{∂E_{total}}{∂W_{3}} = \\frac{∂E_{total}}{∂h_{2}} \\text{×} \\frac{∂h_{2}}{∂z_{2}} \\text{×} \\frac{∂z_{2}}{∂W_{3}}  → W_{3}^{+}=0.39964496\n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "\\frac{∂E_{total}}{∂W_{4}} = \\frac{∂E_{total}}{∂h_{2}} \\text{×} \\frac{∂h_{2}}{∂z_{2}} \\text{×} \\frac{∂z_{2}}{∂W_{4}} → W_{4}^{+}=0.34928991\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **5. 결과 확인**\n",
    "\n",
    "![img](https://wikidocs.net/images/page/37406/nn1_final.PNG)\n",
    "\n",
    "업데이트 된 가중치에 대해서 다시 한 번 순전파를 진행하여 오차가 감소하였는지 확인해보겠습니다.\n",
    "\n",
    "<br>\n",
    "$$\n",
    "z_{1}=W_{1}x_{1} + W_{2}x_{2}=0.29959556 \\text{×} 0.1 + 0.24919112 \\text{×} 0.2= 0.07979778\n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "z_{2}=W_{3}x_{1} + W_{4}x_{2}=0.39964496 \\text{×} 0.1 + 0.34928991 \\text{×} 0.2= 0.10982248\n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "h_{1}=sigmoid(z_{1}) = 0.51993887\n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "h_{2}=sigmoid(z_{2}) = 0.52742806\n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "z_{3}=W_{5}h_{1}+W_{6}h_{2} = 0.43703857 \\text{×} h_{1} + 0.38685205 \\text{×} h_{2} = 0.43126996\n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "z_{4}=W_{7}h_{1}+W_{8}h_{2} = 0.69629578 \\text{×} h_{1} + 0.59624247 \\text{×} h_{2} = 0.67650625\n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "o_{1}=sigmoid(z_{3})=0.60617688\n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "o_{2}=sigmoid(z_{4})=0.66295848\n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "E_{o1}=\\frac{1}{2}(target_{o1}-output_{o1})^{2}=0.02125445\n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "E_{o2}=\\frac{1}{2}(target_{o2}-output_{o2})^{2}=0.00198189\n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "E_{total}=E_{o1}+E_{o2}=0.02323634\n",
    "$$\n",
    "기존의 전체 오차 $E_{total}$가 0.02397190였으므로 1번의 역전파로 오차가 감소한 것을 확인할 수 있습니다. 인공 신경망의 학습은 오차를 최소화하는 가중치를 찾는 목적으로 순전파와 역전파를 반복하는 것을 말합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# **케라스(Keras) 훑어보기**\n",
    "\n",
    "이 책에서는 딥 러닝을 쉽게 할 수 있는 파이썬 라이브러리인 케라스(Keras)를 사용합니다. 케라스는 유저가 손쉽게 딥 러닝을 구현할 수 있도록 도와주는 상위 레벨의 인터페이스입니다. 케라스를 사용하면 딥 러닝을 쉽게 구현할 수 있습니다.\n",
    "\n",
    "케라스의 모든 기능들을 열거하는 것만으로도 하나의 책의 분량이고, 여기서 전부 다룰 수는 없습니다. 가장 좋은 방법은 케라스 공식 문서(https://keras.io/)를 참고하는 것입니다. 여기서는 대표적으로 사용되는 케라스의 도구들을 이해합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. 전처리(Preprocessing)**\n",
    "**Tokenizer()** : 토큰화와 정수 인코딩(단어에 대한 인덱싱)을 위해 사용됩니다. 정수 인코딩 챕터를 참고하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences :  [1, 2, 3, 4, 6, 7] \n",
      "\n",
      "word_index :  {'the': 1, 'earth': 2, 'is': 3, 'an': 4, 'awesome': 5, 'place': 6, 'live': 7}\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "t = Tokenizer()\n",
    "fit_text = \"The earth is an awesome place live\"\n",
    "t.fit_on_texts([fit_text])\n",
    "\n",
    "test_text = \"The earth is an great place live\"\n",
    "sequences = t.texts_to_sequences([test_text])[0]\n",
    "\n",
    "print(\"sequences : \", sequences, \"\\n\") # great는 단어 집합(vocabulary)에 없으므로 출력되지 않는다.\n",
    "print(\"word_index : \", t.word_index) # 단어 집합(vocabulary) 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pad_sequence()** : 전체 훈련 데이터에서 각 샘플의 길이는 서로 다를 수 있습니다. 또는 각 문서 또는 각 문장은 단어의 수가 제각각입니다. 모델의 입력으로 사용하려면 모든 샘플의 길이를 동일하게 맞추어야할 때가 있습니다. 이를 자연어 처리에서는 패딩(padding) 작업이라고 하는데, 보통 숫자 0을 넣어서 길이가 다른 샘플들의 길이를 맞춰줍니다. 케라스에서는 pad_sequence()를 사용합니다. pad_sequence()는 정해준 길이보다 길이가 긴 샘플은 값을 일부 자르고, 정해준 길이보다 길이가 짧은 샘플은 값을 0으로 채웁니다.\n",
    "\n",
    "- **첫번째 인자** = 패딩을 진행할 데이터\n",
    "- **maxlen** = 모든 데이터에 대해서 정규화 할 길이\n",
    "- **padding** = 'pre'를 선택하면 앞에 0을 채우고 'post'를 선택하면 뒤에 0을 채움."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6],\n",
       "       [0, 7, 8]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# 전처리가 끝나서 각 단어에 대한 정수 인코딩이 끝났다고 가정하고, 3개의 데이터를 입력으로 합니다.\n",
    "pad_sequences([[1, 2, 3], [3, 4, 5, 6], [7, 8]], maxlen=3, padding='pre')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **2. 워드 임베딩(Word Embedding)**\n",
    "\n",
    "9챕터에서 다루겠지만 워드 ***임베딩이란 텍스트 내의 단어들을 밀집 벡터(dense vector)로 만드는 것***을 말합니다. 밀집 벡터가 무엇일까요? 이미 배운 개념인 원-핫 벡터와 비교해봅시다. 원-핫 벡터는 대부분이 0의 값을 가지고, 단 하나의 1의 값을 가지는 벡터였습니다. 또한 벡터의 차원이 대체적으로 크다는 성질을 가졌습니다. 원-핫 벡터의 예는 다음과 같습니다.\n",
    "\n",
    "- *Ex) [0 1 0 0 0 0 ... 중략 ... 0 0 0 0 0 0 0] # 차원이 굉장히 크면서 대부분의 값이 0*\n",
    "\n",
    "***대부분의 값이 0인 이러한 벡터를 희소 벡터(sparse vector)라고 합니다. 원-핫 벡터는 희소 벡터의 예***입니다. 원-핫 벡터는 단어의 수만큼 벡터의 차원을 가지며 단어 간 유사도가 모두 동일하다는 단점이 있습니다. 반면, 희소 벡터와 표기상으로도 의미상으로도 반대인 벡터가 있습니다. ***대부분의 값이 실수이고, 상대적으로 저차원인 밀집 벡터(dense vector)입니다. 아래는 밀집 벡터의 예***입니다.\n",
    "\n",
    "- *Ex) [0.1 -1.2 0.8 0.2 1.8] # 상대적으로 저차원이며 실수값을 가짐*\n",
    "\n",
    "간단히 표로 정리하면 아래와 같습니다.\n",
    "\n",
    "|     -     |        원-핫 벡터        |       임베딩 벡터        |\n",
    "| :-------: | :----------------------: | :----------------------: |\n",
    "|   차원    | 고차원(단어 집합의 크기) |          저차원          |\n",
    "| 다른 표현 |     희소 벡터의 일종     |     밀집 벡터의 일종     |\n",
    "| 표현 방법 |           수동           | 훈련 데이터로부터 학습함 |\n",
    "| 값의 타입 |          1과 0           |           실수           |\n",
    "\n",
    "단어를 원-핫 벡터로 만드는 과정을 원-핫 인코딩이라고 하였습니다. 이와 대비적으로 단어를 밀집 벡터로 만드는 작업을 **워드 임베딩(word embedding)**이라고 합니다. 밀집 벡터는 워드 임베딩 과정을 통해 나온 결과므로 임베딩 벡터(embedding vector)라고도 합니다. 원-핫 벡터의 차원이 주로 20,000 이상을 넘어가는 것과는 달리 임베딩 벡터는 주로 256, 512, 1024 등의 차원을 가집니다. 임베딩 벡터는 초기에는 랜덤값을 가지지만, 인공 신경망의 가중치가 학습되는 방법과 같은 방식으로 값이 학습되며 변경됩니다.\n",
    "\n",
    "**Embedding()** : Embedding()은 단어를 밀집 벡터로 만드는 역할을 합니다. 인공 신경망 용어로는 임베딩 층(embedding layer)을 만드는 역할을 합니다. Embedding()은 정수 인코딩이 된 단어들을 입력을 받아서 임베딩을 수행합니다.\n",
    "\n",
    "Embedding()은 (number of samples, input_length)인 ***2D 정수 텐서를 입력***받습니다. 이 때 각 sample은 정수 인코딩이 된 결과로, 정수의 시퀀스입니다. Embedding()은 워드 임베딩 작업을 수행하고 (number of samples, input_length, embedding word dimentionality)인 3D 텐서를 리턴합니다.\n",
    "\n",
    "아래의 코드는 실제 동작되는 코드가 아니라 의사 코드(pseudo-code)로 임베딩의 개념 이해를 돕기 위해서 작성되었습니다.\n",
    "\n",
    "```python\n",
    "# 문장 토큰화와 단어 토큰화\n",
    "text=[['Hope', 'to', 'see', 'you', 'soon'],['Nice', 'to', 'see', 'you', 'again']]\n",
    "\n",
    "# 각 단어에 대한 정수 인코딩\n",
    "text=[[0, 1, 2, 3, 4],[5, 1, 2, 3, 6]]\n",
    "\n",
    "# 위 데이터가 아래의 임베딩 층의 입력이 된다.\n",
    "Embedding(7, 2, input_length=5)\n",
    "# 7은 단어의 개수. 즉, 단어 집합(vocabulary)의 크기이다.\n",
    "# 2는 임베딩한 후의 벡터의 크기이다.\n",
    "# 5는 각 입력 시퀀스의 길이. 즉, input_length이다.\n",
    "\n",
    "# 각 정수는 아래의 테이블의 인덱스로 사용되며 Embeddig()은 각 단어에 대해 임베딩 벡터를 리턴한다.\n",
    "+------------+------------+\n",
    "|   index    | embedding  |\n",
    "+------------+------------+\n",
    "|     0      | [1.2, 3.1] |\n",
    "|     1      | [0.1, 4.2] |\n",
    "|     2      | [1.0, 3.1] |\n",
    "|     3      | [0.3, 2.1] |\n",
    "|     4      | [2.2, 1.4] |\n",
    "|     5      | [0.7, 1.7] |\n",
    "|     6      | [4.1, 2.0] |\n",
    "+------------+------------+\n",
    "# 위의 표는 임베딩 벡터가 된 결과를 예로서 정리한 것이고 Embedding()의 출력인 3D 텐서를 보여주는 것이 아님.\n",
    "```\n",
    "\n",
    "Embedding()에 넣어야하는 대표적인 인자는 다음과 같습니다.\n",
    "\n",
    "**첫번째 인자** = 단어 집합의 크기. 즉, 총 단어의 개수\n",
    "**두번째 인자** = 임베딩 벡터의 출력 차원. 결과로서 나오는 임베딩 벡터의 크기\n",
    "**input_length** = 입력 시퀀스의 길이"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **3. 모델링(Modeling)**\n",
    "\n",
    "**Sequential()** : 인공 신경망 챕터에서 입력층, 은닉층, 출력층에 대해서 배웠습니다. 케라스에서는 이러한 층을 구성하기 위해 Sequential()을 사용합니다. Sequential()을 model로 선언한 뒤에 model.add()라는 코드를 통해 층을 단계적으로 추가합니다. 아래는 model.add()로 층을 추가하는 예제 코드를 보여줍니다. 실제로는 괄호 사이에 있는 온점 대신에 실제 층의 이름을 기재해야 합니다.\n",
    "\n",
    "```python\n",
    "from keras.models import Sequential\n",
    "model = Sequential()\n",
    "\n",
    "# 실제로는 괄호 사이에 있는 온점 대신에 실제 층의 이름을 기재해야 합니다.\n",
    "model.add(...) # 층 추가\n",
    "model.add(...) # 층 추가\n",
    "model.add(...) # 층 추가\n",
    "```\n",
    "\n",
    "Embedding()을 통해 생성하는 임베딩 층(embedding layer) 또한 인공 신경망의 층의 하나이므로 model.add()로 추가해야합니다.\n",
    "\n",
    "```python\n",
    "from keras.models import Sequential\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(vocabulary, output_dim, input_length))\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dense() :** 전결합층(fully-conntected layer)을 추가합니다. model.add()를 통해 추가할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\young\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, input_dim=3, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=3, init='uniform', activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 코드에서 Dense()는 한번 사용되었지만 더 많은 층을 추가할 수 있습니다. Dense()의 대표적인 인자를 보겠습니다.\n",
    "\n",
    "- **첫번째 인자** = 출력 뉴런의 수.\n",
    "- **input_dim** = 입력 뉴런의 수. (입력의 차원)\n",
    "- **init** = 가중치 초기화 방법.\n",
    "  - uniform : 균일 분포\n",
    "  - normal : 가우시안 분포\n",
    "- **activation** = 활성화 함수.\n",
    "  - linear : 디폴트 값으로 별도 활성화 함수 없이 입력 뉴런과 가중치의 계산 결과 그대로 출력. Ex) 선형 회귀\n",
    "  - sigmoid : 시그모이드 함수. 이진 분류 문제에서 출력층에 주로 사용되는 활성화 함수.\n",
    "  - softmax : 소프트맥스 함수. 셋 이상을 분류하는 다중 클래스 분류 문제에서 출력층에 주로 사용되는 활성화 함수.\n",
    "  - relu : 렐루 함수. 은닉층에 주로 사용되는 활성화 함수.\n",
    "\n",
    "위 코드에서 사용된 Dense()의 의미를 보겠습니다. 첫번째 인자의 값은 1인데 이는 총 1개의 출력 뉴런을 의미합니다. Dense()의 두번째 인자인 input_dim은 입력층의 뉴런 수를 의미합니다. 이 경우에는 3입니다. 3개의 입력층 뉴런과 1개의 출력층 뉴런을 만들었습니다. 이를 시각화하면 다음과 같습니다.\n",
    "\n",
    "![img](https://wikidocs.net/images/page/32105/neural_network1.PNG)\n",
    "\n",
    "이제 Dense()를 사용하여 전결합층을 하나 더 추가해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\young\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, input_dim=4, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=4, init='uniform', activation='relu'))\n",
    "model.add(Dense(1, actvation='sigmoid')) # i출력층"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번에는 Dense()가 두번 사용되었습니다. Dense()가 처음 사용되었을 때와 추가로 사용되었을 때의 인자는 조금 다릅니다. 이제 첫번째 사용된 Dense()의 8이라는 값은 더 이상 출력층의 뉴런이 아니라 은닉층의 뉴런입니다. 뒤에 층이 하나 더 생겼기 때문입니다.\n",
    "\n",
    "두번째 Dense()는 input_dim 인자가 없는데, 이는 이미 이전층의 뉴런의 수가 8개라는 사실을 알고있기 때문입니다. 위의 코드에서 두번째 Dense()는 마지막 층이므로, 첫번째 인자 1은 결국 출력층의 뉴런의 개수가 됩니다. 이를 시각화하면 다음과 같습니다.\n",
    "\n",
    "![img](https://wikidocs.net/images/page/32105/neural_network2.PNG)\n",
    "\n",
    "이 외에도 LSTM, GRU, Convolution2D, BatchNormalization 등 다양한 층을 만들 수 있습니다. 일부는 뒤의 챕터에서 배우게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**summary()** : 모델의 정보를 요약해서 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 49\n",
      "Trainable params: 49\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 위의 코드의 연장선상에 있는 코드임.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **4. 컴파일(Compile)과 훈련(Training)**\n",
    "**compile()** : 모델을 기계가 이해할 수 있도록 컴파일 합니다. 오차 함수와 최적화 방법, 메트릭 함수를 선택할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 코드는 뒤의 텍스트 분류 챕터의 스팸 메일 분류하기 실습 코드를 갖고온 것임.\n",
    "from keras.layers import SimpleRNN, Embedding, Dense\n",
    "from keras.models import Sequential\n",
    "max_features = 10000\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(SimpleRNN(32)) #RNN에 대한 설명은 뒤의 챕터에서 합니다.\n",
    "model.add(Dense(1, activation = \"sigmoid\"))\n",
    "model.compile(optimizer = \"rmsprop\", loss = \"binary_crossentropy\", metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 코드는 임베딩층, 은닉층, 출력층을 추가하여 모델을 설계한 후에, 마지막으로 컴파일 하는 과정을 보여줍니다.\n",
    "\n",
    "- **optimizer** : 훈련 과정을 설정하는 옵티마이저를 설정합니다. 'adam'이나 'sgd'와 같이 문자열로 지정할 수도 있습니다.\n",
    "- **loss** : 훈련 과정에서 사용할 손실 함수(loss function)를 설정합니다.\n",
    "- **metrics** : 훈련을 모니터링하기 위한 지표를 선택합니다.\n",
    "\n",
    "대표적으로 사용되는 손실 함수와 활성화 함수의 조합은 아래와 같습니다. 더 많은 함수는 케라스 공식문서에서 확인 가능합니다.\n",
    "\n",
    "|    문제 유형     |                   손실 함수명                   | 출력층의 활성화 함수명 |                          참고 설명                           |\n",
    "| :--------------: | :---------------------------------------------: | :--------------------: | :----------------------------------------------------------: |\n",
    "|    회귀 문제     |       mean_squared_error(평균 제곱 오차)        |           -            |                              -                               |\n",
    "| 다중 클래스 분류 | categorical_crossentropy (범주형 교차 엔트로피) |       소프트맥스       |            10챕터 로이터 뉴스 분류하기 실습 참고             |\n",
    "| 다중 클래스 분류 |         sparse_categorical_crossentropy         |       소프트맥스       | 범주형 교차 엔트로피와 동일하지만 이 경우 원-핫 인코딩이 된 상태일 필요없이 정수 인코딩 된 상태에서 수행 가능. |\n",
    "|    이진 분류     |     binary_crossentropy(이항 교차 엔트로피)     |       시그모이드       | 10챕터 스팸 메일 분류하기, IMDB 리뷰 감성 분류하기 실습 참고 |\n",
    "\n",
    "이진 분류(Binary Classification)와 다중 클래스 분류(Multi-class Classification)에 대해서는 10챕터에서 학습합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**fit()** : 모델을 학습합니다. 모델이 오차로부터 매개 변수를 업데이트 시키는 과정을 학습, 훈련, 또는 적합(fitting)이라고 하기도 하는데, 모델이 데이터에 적합해가는 과정이기 때문입니다. 그런 의미에서 fit()은 모델의 훈련을 시작한다는 의미를 가지고 있습니다.\n",
    "\n",
    "```python\n",
    "# 위의 compile() 코드의 연장선상인 코드\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "```\n",
    "\n",
    "- **첫번째 인자** = 훈련 데이터에 해당됨.\n",
    "- **두번째 인자** = 지도 학습 관점에서 레이블 데이터에 해당됨.\n",
    "- **epochs** = 에포크라고 읽으며 에포크 1은 전체 데이터를 한 차례 훑고 지나갔음을 의미함. 정수값 기재 필요. 총 훈련 횟수를 정의함.\n",
    "- **batch_size** = 배치 크기. 기본값은 32. 미니 배치 경사 하강법을 사용하고 싶지 않을 경우에는 batch_size=None을 통해 선택 가능.\n",
    "\n",
    "\n",
    "좀 더 많은 인자를 사용할 때를 보겠습니다.\n",
    "\n",
    "```python\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0, validation_data(X_val, y_val))\n",
    "\n",
    "# validation_split: 훈련 데이터의 20%를 검증 데이터로 사용.\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0, validation_split=0.2))\n",
    "```\n",
    "\n",
    "- **validation_data(x_val, y_val)** = 검증 데이터(validation data)를 사용합니다. 검증 데이터를 사용하면 각 에포크마다 검증 데이터의 정확도도 함께 출력되는데, 이 정확도는 훈련이 잘 되고 있는지를 보여줄 뿐이며 실제로 모델이 검증 데이터를 학습하지는 않습니다. 검증 데이터의 loss가 낮아지다가 높아지기 시작하면 이는 과적합(overfitting)의 신호입니다.\n",
    "\n",
    "- **validation_split**= validation_data 대신 사용할 수 있습니다. 검증 데이터를 사용하는 것은 동일하지만, 별도로 존재하는 검증 데이터를 주는 것이 아니라 X_train과 y_train에서 일정 비율을 분리하여 이를 검증 데이터로 사용합니다. 역시나 훈련 자체에는 반영되지 않고 훈련 과정을 지켜보기 위한 용도로 사용됩니다.\n",
    "\n",
    "- **verbose** = 학습 중 출력되는 문구를 설정합니다.\n",
    "  - 0 : 아무 것도 출력하지 않습니다.\n",
    "  -  2 : 에포크 횟수당 한 줄씩 출력합니다.\n",
    "  - 1 : 훈련의 진행도를 보여주는 진행 막대를 보여줍니다.\n",
    "\n",
    "아래는 verbose의 값이 2일 때와 1일 때를 보여줍니다.\n",
    "\n",
    "```python\n",
    "# verbose = 2일 경우.\n",
    "Epoch 88/100\n",
    " - 0s - loss: 0.1475 - acc: 1.0000\n",
    "            \n",
    "# verbose = 1일 경우.\n",
    "Epoch 88/100\n",
    "7/7 [==============================] - 0s 143us/step - loss: 0.1029 - acc: 1.0000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **5. 평가(Evaluation)와 예측(Prediction)**\n",
    "\n",
    "**evaluate()** : 테스트 데이터를 통해 학습한 모델에 대한 정확도를 평가합니다.\n",
    "\n",
    "```python\n",
    "# 위의 fit() 코드의 연장선상인 코드\n",
    "model.evaluate(X_test, y_test, batch_size=32)\n",
    "```\n",
    "\n",
    "- 첫번째 인자 = 테스트 데이터에 해당됨.\n",
    "- 두번째 인자 = 지도 학습 관점에서 레이블 테스트 데이터에 해당됨.\n",
    "- batch_size = 배치 크기.\n",
    "\n",
    "**predict()** : 임의의 입력에 대한 모델의 출력값을 확인합니다.\n",
    "\n",
    "```python\n",
    "# 위의 fit() 코드의 연장선상인 코드\n",
    "model.predict(X_input, batch_size=32)\n",
    "```\n",
    "\n",
    "- 첫번째 인자 = 예측하고자 하는 데이터.\n",
    "- batch_size = 배치 크기."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **6. 모델의 저장(Save)과 로드(Load)**\n",
    "\n",
    "복습을 위한 스터디나 실제 어플리케이션 개발 단계에서 구현한 모델을 저장하고 불러오는 일은 중요합니다. 모델을 저장한다는 것은 학습이 끝난 신경망의 구조를 보존하고 계속해서 사용할 수 있다는 의미입니다.\n",
    "\n",
    "**save()** : 인공 신경망 모델을 hdf5 파일에 저장합니다.\n",
    "\n",
    "```python\n",
    "model.save(\"model_name.h5\")\n",
    "```\n",
    "\n",
    "**load_model()** : 저장해둔 모델을 불러옵니다.\n",
    "\n",
    "```python\n",
    "from keras.models import load_model\n",
    "model = load_model(\"model_name.h5\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **7. 함수형 API(functional API)**\n",
    "\n",
    "이 책의 대부분의 실습은 위에서 배운 Sequential API를 통해 이루어집니다. 위의 코드들은 사용하기에 매우 간단하지만, 복잡한 모델을 설계하기 위해서는 부족함이 있습니다. 이에 이 책에서는 케라스의 또 다른 사용법인 functional API에 대해서도 배웁니다. 당장 이해하기에 어렵다면, 여기서는 우선 넘어가고 functional API가 나오는 실습 부분이 나올 때 다시 돌아와서 학습하셔도 좋습니다.\n",
    "\n",
    "함수형 API는 위키독스에서는 별도의 챕터로 작성되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**참고사이트**\n",
    "* https://www.tensorflow.org/alpha/guide/keras/overview?hl=ko\n",
    "* https://machinelearningmastery.com/build-multi-layer-perceptron-neural-network-models-keras/\n",
    "* https://realpython.com/python-keras-text-classification/#your-first-keras-model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# **케라스의 함수형 API(Keras Functional API)**\n",
    "\n",
    "앞에서 케라스를 사용하여 모델을 설계하는 방식을 sequential API를 사용하였다고 합니다. 그런데 sequential API는 여러층을 공유하거나 다양한 종류의 입력과 출력을 사용하는 등의 복잡한 모델을 만드는 일을 하기에는 한계가 있습니다. 이번에는 복잡한 모델을 생성할 수 있는 방식인 functional API에 대해서 알아봅니다.\n",
    "\n",
    "functional API에 대한 자세한 소개는 케라스 공식 문서에서도 확인할 수 있습니다.\n",
    "\n",
    "- 링크 : https://keras.io/getting-started/functional-api-guide/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **1. sequential API로 만든 모델**\n",
    "\n",
    "두 가지 API의 차이를 이해하기 위해서 앞서 배운 sequential API를 사용하여 기본적인 모델을 만들어봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 코드는 소프트맥스 회귀 챕터에서 가져온 코드임.\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model= Sequential()\n",
    "\n",
    "model.add(Dense(3, input_dim=4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같은 방식은 직관적이고 편리하지만 단순히 층을 쌓는 것만으로는 구현할 수 없는 복잡한 인공 신경망을 구현할 수 없습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **2. functional API로 만든 모델**\n",
    "\n",
    "functional API는 각 층을 일종의 함수(function)로서 정의합니다. 그리고 각 함수를 조합하기 위한 연산자들을 제공하는데, 이를 이용하여 신경망을 설계합니다. functional API로 FFNN, RNN 등 다양한 모델을 만들면서 기존의 sequential API와의 차이를 이해해봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) 전결합 피드 포워드 신경망(Fully-connected FFNN)**\n",
    "\n",
    "sequential API와는 다르게 functional API에서는 입력 데이터의 크기(shape)를 인자로 입력층을 정의해주어야 합니다. 여기서는 입력의 차원이 1인 전결합 피드 포워드 신경망(Fully-connected FFNN)을 만든다고 가정해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "\n",
    "# 텐서를 리턴한다.\n",
    "inputs = Input(shape=(10,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 코드는 10개의 입력을 받는 입력층을 보여줍니다. 이제 위의 코드에 은닉층과 출력층을 추가해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "\n",
    "inputs = Input(shape=(10,)) # 입력층\n",
    "hidden1 = Dense(64, activation='relu')(inputs) # 은닉층_01\n",
    "hidden2 = Dense(64, activation='relu')(hidden1) # 은닉층_02\n",
    "output = Dense(1, activation='sigmoid')(hidden2) # 출력층"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 위의 코드를 하나의 모델로 구성해보겠습니다. 이는 Model에 입력 텐서와 출력 텐서를 정의하여 완성됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "inputs = Input(shape=(10,))\n",
    "hidden1 = Dense(64, activation='relu')(inputs)\n",
    "hidden2 = Dense(64, activation='relu')(hidden1)\n",
    "output = Dense(1, activation='sigmoid')(hidden2)\n",
    "model = Model(inputs=inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지의 내용을 정리하면 다음과 같습니다.\n",
    "\n",
    "- Input() 함수에 입력의 크기를 정의합니다.\n",
    "- 이전층을 다음층 함수의 입력으로 사용하고, 변수에 할당합니다.\n",
    "- Model() 함수에 입력과 출력을 정의합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 이를 model로 저장하면 sequential API를 사용할 때와 마찬가지로 model.compile, model.fit 등을 사용 가능합니다.\n",
    "\n",
    "```python\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(data, labels)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번에는 변수명을 달리해서 FFNN을 만들어보겠습니다. 이번에는 은닉층과 출력층의 변수를 전부 x로 통일하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(10,))\n",
    "x = Dense(8, activation=\"relu\")(inputs)\n",
    "x = Dense(4, activation=\"relu\")(x)\n",
    "x = Dense(1, activation=\"linear\")(x)\n",
    "model = Model(inputs, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번에는 위에서 배운 내용을 바탕으로 선형 회귀와 로지스틱 회귀를 functional API로 구현해봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) 선형 회귀(Linear Regression)**\n",
    "\n",
    "```python\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "inputs = Input(shape=(3,))\n",
    "output = Dense(1, activation='linear')(inputs)\n",
    "linear_model = Model(inputs, output)\n",
    "\n",
    "linear_model.compile(optimizer='sgd', loss='mse')\n",
    "linear_model.fit(x=dat_test, y=y_cts_test, epochs=50, verbose=0)\n",
    "linear_model.fit(x=dat_test, y=y_cts_test, epochs=1, verbose=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3) 로지스틱 회귀(Logistic Regression)**\n",
    "\n",
    "```python\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "inputs = Input(shape=(3,))\n",
    "output = Dense(1, activation='sigmoid')(inputs)\n",
    "logistic_model = Model(inputs, output)\n",
    "\n",
    "logistic_model.compile(optimizer='sgd', loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "logistic_model.optimizer.lr = 0.001\n",
    "logistic_model.fit(x=dat_train, y=y_classifier_train, epochs = 5, validation_data = (dat_test, y_classifier_test))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4) 다중 입력을 받는 모델(model that accepts multiple inputs)**\n",
    "\n",
    "functional API를 사용하면 아래와 같이 다중 입력과 다중 출력을 가지는 모델도 만들 수 있습니다.\n",
    "\n",
    "```\n",
    "# 최종 완성된 다중 입력, 다중 출력 모델의 예\n",
    "model=Model(inputs=[a1, a2], outputs=[b1, b2, b3]\n",
    "```\n",
    "\n",
    "이번에는 다중 입력을 받는 모델을 입력층부터 출력층까지 설계해보겠습니다.\n",
    "\n",
    "```python\n",
    "from keras.layers import Input, Dense, concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "# 두 개의 입력층을 정의\n",
    "inputA = Input(shape=(64,))\n",
    "inputB = Input(shape=(128,))\n",
    "\n",
    "# 첫번째 입력층으로부터 분기되어 진행되는 인공 신경망 정의\n",
    "x = Dense(16, activation='relu')(inputA)\n",
    "x = Dense(8, activation='relu')(x)\n",
    "x = Model(inputs=inputA, outputs=x)\n",
    "\n",
    "# 두번째 입력층으로부터 분기되어 진행되는 인공 신경망을 정의\n",
    "y = Dense(64, activation='relu')(inputB)\n",
    "y = Dense(32, activation='relu')(y)\n",
    "y = Dense(8, activation='relu')(y)\n",
    "y = Model(inputs=inputB, outputs=y)\n",
    "\n",
    "# 두개의 인공 신경망의 출력을 연결(concatenate)\n",
    "result = concatenate([x.output, y.output])\n",
    "\n",
    "# 연결된 값을 입력으로 받는 밀집층을 추가(Dense layer)\n",
    "z = Dense(2, activation='relu')(result)\n",
    "\n",
    "# 선형 회귀를 위해 activation=linear를 설정\n",
    "z = Dense(1, activation='linear')(z)\n",
    "\n",
    "# 결과적으로 이 모델은 두 개의 입력층으로부터 분기되어 진행된 후 마지막에는 하나의 출력을 예측하는 모델이 됨.\n",
    "model = Model(inputs=[x.input, y.input], outputs=z)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5) RNN(Recurrence Neural Network) 은닉층 사용하기**\n",
    "\n",
    "이번에는 RNN 은닉층을 가지는 모델을 설계해봅시다. 여기서는 하나의 특성(feature)에 50개의 시점(time-step)을 입력으로 받는 모델을 설계해보겠습니다. RNN에 대한 구체적인 사항은 다음 챕터에서 배웁니다.\n",
    "\n",
    "```python\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Model\n",
    "\n",
    "inputs = Input(shape=(50,1))\n",
    "lstm_layer = LSTM(10)(inputs) # RNN의 일종인 LSTM을 사용\n",
    "x = Dense(10, activation='sigmoid')(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "```\n",
    "\n",
    "다수의 입력과 다수의 출력을 가지는 좀 더 다양한 예제는 앞서 소개한 케라스 공식 문서에서 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6) 다르게 보이지만 동일한 표기**\n",
    "\n",
    "케라스의 functional API가 익숙하지 않은 상태에서 functional API를 사용한 코드를 보다가 혼동할 수 있는 점이 한 가지 있습니다. 바로 동일한 의미를 가지지만, 하나의 줄로 표현할 수 있는 코드를 두 개의 줄로 표현한 경우입니다.\n",
    "\n",
    "```python\n",
    "encoder = Dense(128)(input)\n",
    "```\n",
    "\n",
    "위 코드는 아래와 같이 두 개의 줄로 표현할 수 있습니다.\n",
    "\n",
    "```python\n",
    "encoder = Dense(128)\n",
    "encoder(input)\n",
    "```\n",
    "\n",
    "------\n",
    "- 참고사이트\n",
    "https://regressionsessionsblog.wordpress.com/2018/04/17/keras-functional-api/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# **피드 포워드 신경망 언어 모델(Neural Network Language Model, NNLM)**\n",
    "\n",
    "파이썬 등과 같은 프로그래밍 언어를 사용할 때는 명세되어져 있는 튜플, 클래스 등과 같은 용어와 작성할 때 지켜야 하는 문법을 바탕으로 코드를 작성합니다. 문법에 맞지 않으면 에러가 발생하므로 명세된 규칙을 지키는 것은 필수적입니다.\n",
    "\n",
    "자연어는 어떨까요? 자연어에도 문법이라는 규칙이 있기는 하지만, 많은 예외 사항, 시간에 따른 언어의 변화, 중의성과 모호성 문제 등을 전부 명세하기란 어렵습니다. 기계가 자연어를 표현하도록 규칙으로 명세하기가 어려운 상황에서 대안은 규칙 기반 접근이 아닌 기계가 주어진 자연어 데이터를 학습하게 하는 것입니다.\n",
    "\n",
    "과거에는 기계가 자연어를 학습하게 하는 방법으로 통계적인 접근을 사용했으나, 최근에는 인공 신경망을 사용하는 방법이 자연어 처리에서 더 좋은 성능을 얻고 있습니다. 번역기, 음성 인식 등과 같이 자연어 생성(Natural Language Generation, NLG)의 기반으로 사용되는 언어 모델도 마찬가지입니다. 통계적 언어 모델(Statistical Language Model, SLM)에서 다양한 구조의 인공 신경망을 사용한 언어 모델들로 대체되기 시작했습니다.\n",
    "\n",
    "- ***통계적 언어 모델 -> 다양한 구조의 인공 신경망 모델***\n",
    "\n",
    "여기서는 신경망 언어 모델의 시초인 ***피드 포워드 신경망 언어 모델(Feed Forward Neural Network Language Model)에 대해서 학습***합니다. 간단히 줄여서 NNLM이라고도 합시다. 뒤의 챕터에서 RNNLM, BiLM 등의 보다 발전된 신경망 언어 모델들을 배웁니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. 기존 N-gram 언어 모델의 한계**\n",
    "\n",
    "언어 모델은 이전 단어들이 주어졌을 때, 다음 단어를 예측하는 일을 합니다. 그래서 언어 모델을 사용하여 이전 단어들이 주어졌을 때, 다음 단어를 예측하는 일을 -ing를 붙여서 **언어 모델링(Language Modeling)**이라고 합니다.\n",
    "\n",
    "```python\n",
    "# 다음 단어 예측하기\n",
    "An adorable little boy is spreaing ____\n",
    "```\n",
    "\n",
    "위 문장을 가지고 앞서 배운 n-gram 언어 모델이 언어 모델링을 하는 방법을 복습해봅시다.\n",
    "\n",
    "![img](https://wikidocs.net/images/page/21692/n-gram.PNG)\n",
    "\n",
    "n-gram 언어 모델은 언어 모델링에 바로 앞의 n-1개의 단어만 참고합니다. 4-gram 언어 모델이라고 가정해봅시다. 모델은 바로 앞 3개의 단어만 참고하며 더 앞의 단어들은 무시합니다. 위 예제에서 다음 단어 예측에 사용되는 단어는 boy, is, spreading입니다.\n",
    "\n",
    "<br>\n",
    "$$\n",
    "P(w\\text{|boy is spreading}) = \\frac{\\text{count(boy is spreading}\\ w)}{\\text{count(boy is spreading)}}\n",
    "$$\n",
    "<br>\n",
    "\n",
    "그 후에는 훈련 코퍼스에서 (n-1)-gram을 카운트한 것을 분모로, n-gram을 카운트한 것을 분자로 하여 다음 단어가 등장 확률을 예측했습니다. 예를 들어 갖고있는 코퍼스에서\n",
    "\n",
    "- boy is spreading가 1,000번\n",
    "- boy is spreading insults가 500번\n",
    "- boy is spreading smiles가 200번 등장했다면\n",
    "\n",
    "각 확률은 아래와 같습니다.\n",
    "\n",
    "<br>\n",
    "$$\n",
    "P(\\text{insults|boy is spreading}) = 0.500\n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "P(\\text{smiles|boy is spreading}) = 0.200\n",
    "$$\n",
    "<br>\n",
    "\n",
    "하지만 이러한 n-gram 언어 모델은 충분한 데이터를 관측하지 못하면 언어를 정확히 모델링하지 못하는 **희소 문제(sparsity problem)**가 있었습니다. 예를 들어 훈련 코퍼스에 $\\text{boy is spreading smile}$라는 단어 시퀀스가 존재하지 않으면 n-gram 언어 모델에서 해당 단어 시퀀스의 확률 $P(\\text{smiles|boy is spreading})$는 0이 되버립니다. 이는 언어 모델이 예측하기에 boy is spreading 다음에는 smiles이란 단어가 나올 수 없다는 의미이지만 해당 단어 시퀀스는 현실에서 실제로는 많이 사용되므로 제대로 된 모델링이 아닙니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **2. 단어의 의미적 유사성**\n",
    "\n",
    "희소 문제는 기계가 단어 간 유사도를 알수 있다면 해결할 수 있는 문제입니다. 실제 제 사례를 이야기해보겠습니다. 저는 최근 '톺아보다'라는 생소한 단어를 배웠고, '톺아보다'가 '샅샅이 살펴보다'와 유사한 의미임을 학습했습니다. 그리고 '발표 자료를 살펴보다'라는 표현 대신 '발표 자료를 톺아보다'라는 표현을 써봤습니다. 저는 '발표 자료를 톺아보다'라는 예문을 어디서 읽은 적은 없지만 두 단어가 유사함을 학습하였으므로 단어를 대신 선택하여 자연어 생성을 할 수 있었습니다.\n",
    "\n",
    "기계도 마찬가지입니다. '보도 자료를 살펴보다'라는 단어 시퀀스는 존재하지만, '발표 자료를 톺아보다'라는 단어 시퀀스는 존재하지 않는 코퍼스를 학습한 언어 모델이 있다고 가정해봅시다. 언어 모델은 아래 선택지에서 다음 단어를 예측해야 합니다.\n",
    "\n",
    "<br>\n",
    "$$\n",
    "P(\\text{톺아보다|보도 자료를})\n",
    "$$\n",
    "\n",
    "<br>\n",
    "$$\n",
    "P(\\text{냠냠하다|보도 자료를})\n",
    "$$\n",
    "<br>\n",
    "\n",
    "저는 '살펴보다'와 '톺아보다'의 유사성을 학습하였고 이를 근거로 두 선택지 중에서 '톺아보다'가 더 맞는 선택이라고 판단할 수 있습니다. 하지만 n-gram 언어 모델은 '보도 자료를' 다음에 '톺아보다'가 나올 확률 $P(\\text{톺아보다|보도 자료를})$를 0으로 연산합니다. n-gram 언어 모델은 '살펴보다'와 '톺아보다'의 단어의 유사도를 학습한 적이 없으며, 예측에 고려할 수 없습니다.\n",
    "\n",
    "만약이 언어 모델 또한 단어의 유사도를 학습할 수 있도록 설계한다면, 훈련 코퍼스에 없는 단어 시퀀스에 대한 예측이라도 유사한 단어가 사용된 단어 시퀀스를 참고하여 보다 정확한 예측을 할 수 있을 겁니다. 그리고 이런 아이디어를 가지고 탄생한 언어 모델이 신경망 언어 모델 **NNLM**입니다. 그리고 이 아이디어는 단어 간 유사도를 반영한 벡터를 만드는 **워드 임베딩(word embedding)**의 아이디어이기도 합니다. 이제 NNLM이 어떻게 훈련 과정에서 단어의 유사도를 학습할 수 있는지 알아봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **3. 피드 포워드 신경망 언어 모델(NNLM)**\n",
    "\n",
    "NNLM이 언어 모델링을 학습하는 과정을 보겠습니다. 이해를 위해 매우 간소화 된 형태로 설명합니다.\n",
    "\n",
    "- **예문 : \"what will the fat cat sit on\"**\n",
    "\n",
    "예를 들어 훈련 코퍼스에 위와 같은 문장이 있다고 해봅시다. 언어 모델은 주어진 단어 시퀀스로부터 다음 단어를 예측하는 모델입니다. 훈련 과정에서는 'what will the fat cat'이라는 단어 시퀀스가 입력으로 주어지면, 다음 단어 'sit'을 예측하는 방식으로 훈련됩니다.\n",
    "\n",
    "훈련 코퍼스가 준비된 상태에서 가장 먼저 해야 할 일은 기계가 단어를 인식할 수 있도록 모든 단어를 숫자로 인코딩 하는 것입니다. 훈련 코퍼스에 7개의 단어만 존재한다고 가정했을 때 위 단어들에 대해서 다음과 같이 원-핫 인코딩을 할 수 있습니다.\n",
    "\n",
    "```python\n",
    "what = [1, 0, 0, 0, 0, 0, 0]\n",
    "will = [0, 1, 0, 0, 0, 0, 0]\n",
    "the = [0, 0, 1, 0, 0, 0, 0]\n",
    "fat = [0, 0, 0, 1, 0, 0, 0]\n",
    "cat = [0, 0, 0, 0, 1, 0, 0]\n",
    "sit = [0, 0, 0, 0, 0, 1, 0]\n",
    "on = [0, 0, 0, 0, 0, 0, 1]\n",
    "```\n",
    "\n",
    "모든 단어가 단어 집합(vocabulary)의 크기인 7의 차원을 가지는 원-핫 벡터가 되었습니다. 이제 이 원-핫 벡터들이 훈련을 위한 NNLM의 입력이면서 예측을 위한 레이블이기도 합니다. 'what will the fat cat'를 입력을 받아서 'sit'을 예측하는 일은 기계에게 실제로는\n",
    "\n",
    "- ***what, will, the, fat, cat의 원-핫 벡터를 입력받아***\n",
    "- ***sit의 원-핫 벡터를 예측하는 문제가 됩니다.***\n",
    "\n",
    "NNLM은 n-gram 언어 모델과 유사하게 다음 단어를 예측할 때, 앞의 모든 단어를 참고하는 것이 아니라 정해진 n개의 단어만을 참고합니다. 예를 들어 n을 4라고 해봅시다. 이때, 언어 모델은 'what will the fat cat'라는 단어 시퀀스가 주어졌을 때, 다음 단어를 예측하기 위해 앞의 4개 단어 'will the fat cat'까지만 참고하고 그 앞 단어인 what은 무시합니다. 이 범위를 윈도우(window)라고 하기도 하는데. 여기서 윈도우의 크기 n은 4입니다.\n",
    "\n",
    "![img](https://wikidocs.net/images/page/45609/nnlm1.PNG)\n",
    "\n",
    "NNLM의 구조를 보겠습니다. NNLM은 위의 그림과 같이 총 4개의 층(layer)으로 이루어진 인공 신경망입니다. 우선 입력층(input layer)을 봅시다. 앞에서 윈도우의 크기는 4로 정하였으므로 입력은 4개의 단어 'what, will, the, fat'의 원-핫 벡터입니다. 이제 출력층(Output layer)를 봅시다. 모델이 예측해야하는 정답에 해당되는 단어 sit의 원-핫 벡터는 출력층에서 모델이 예측한 값의 오차를 구하기 위해 사용될 예정입니다. 그리고 이 오차로부터 손실 함수를 사용해 인공 신경망이 학습을 하게 됩니다. 이제 내부 메커니즘을 따라가봅시다.\n",
    "\n",
    "4개의 원-핫 벡터를 입력 받은 NNLM은 다음층인 투사층(projection layer)을 지나게 됩니다. 인공 신경망에서 입력층과 출력층 사이의 층은 보통 은닉층이라고 부르는데, 여기서 투사층이 일반 은닉층과 구별되는 특징은 가중치 행렬과의 연산은 이루어지지만 활성화 함수가 존재하지 않는다는 것입니다.\n",
    "\n",
    "투사층의 크기를 M으로 설정하면, 각 입력 단어들은 투사층에서 V × M 크기의 가중치 행렬과 곱해집니다. 여기서 V는 단어 집합의 크기를 의미합니다. 만약 원-핫 벡터의 차원이 7이고, M이 5라면 가중치 행렬 W는 7 × 5 행렬이 됩니다.\n",
    "\n",
    "![img](https://wikidocs.net/images/page/45609/nnlm2_renew.PNG)\n",
    "\n",
    "각 단어의 원-핫 벡터와 가중치 W 행렬의 곱이 어떻게 이루어지는지 보겠습니다. 위 그림에서는 각 원-핫 벡터를 x로 표기하였습니다. 원-핫 벡터의 특성으로 인해 i번째 인덱스에 1이라는 값을 가지고 그 외의 0의 값을 가지는 원-핫 벡터와 가중치 W 행렬의 곱은 사실 W행렬의 i번째 행을 그대로 읽어오는 것과(lookup) 동일합니다. 그래서 이 작업을 룩업 테이블(lookup table)이라고 부릅니다.\n",
    "\n",
    "이 테이블 룩업 작업을 거치면 V의 차원을 가지는 **원-핫 벡터**는 이보다 더 차원이 작은 M차원의 단어 벡터로 맵핑됩니다. 위 그림에서는 단어 fat을 의미하는 원-핫 벡터를 $x_{fat}$으로 표현했고, 테이블 룩업 과정을 거친 후의 단어 벡터는 $e_{fat}$으로 표현했습니다. 이 벡터들은 초기에는 랜덤한 값을 가지지만 학습 과정에서 값이 계속 변경되는데 이 단어 벡터를 **임베딩 벡터(embedding vector)**라고 합니다.\n",
    "\n",
    "![img](https://wikidocs.net/images/page/45609/nnlm3_renew.PNG)\n",
    "\n",
    "각 단어가 테이블 룩업을 통해 임베딩 벡터로 변경되고, 투사층에서 모든 임베딩 벡터들의 값은 연결(concatenation)이 됩니다. x를 각 단어의 원-핫 벡터, NNLM이 예측하고자 하는 단어가 문장에서 t번째 단어라고 하고, 윈도우의 크기를 n, 룩업 테이블을 의미하는 함수를 lookup, 세미콜론(;)을 연결 기호로 하였을 때 투사층을 식으로 표현하면 아래와 같습니다.\n",
    "\n",
    "**투사층:**\n",
    "\n",
    "<br>\n",
    "$$\n",
    "p^{layer} = (lookup(x_{t-n}); ...; lookup(x_{t-2}); lookup(x_{t-1})) = (e_{t-n}; ...; e_{t-2}; e_{t-1})\n",
    "$$\n",
    "<br>\n",
    "\n",
    "일반적인 은닉층이 활성화 함수를 사용하는 비선형층(nonlinear layer)인 것과는 달리 투사층은 활성화 함수가 존재하지 않는 선형층(linear layer)이라는 점이 다소 생소하지만, 이 다음부터는 다시 은닉층을 사용하므로 일반적인 피드 포워드 신경망과 동일합니다.\n",
    "\n",
    "![img](https://wikidocs.net/images/page/45609/nnlm4.PNG)\n",
    "\n",
    "투사층의 결과는 h의 크기를 가지는 은닉층을 지납니다. 일반적인 피드 포워드 신경망에서 은닉층을 지난다는 것은 은닉층의 입력은 가중치 곱해진 후 편향이 더해져 활성화 함수의 입력이 된다는 의미입니다. 이때의 가중치와 편향을 Wh와 bh이라고 하고, 은닉층의 활성화 함수를 하이퍼볼릭탄젠트 함수라고 하였을 때, 은닉층을 식으로 표현하면 아래와 같습니다.\n",
    "\n",
    "**은닉층:**\n",
    "\n",
    "<br>\n",
    "$$\n",
    "h^{layer} = tanh(W_{h}p^{layer} + b_{h})\n",
    "$$\n",
    "<br>\n",
    "\n",
    "![img](https://wikidocs.net/images/page/45609/nnlm5_final.PNG)\n",
    "\n",
    "은닉층의 출력은 이제 V의 크기를 가지는 출력층으로 향합니다. 이 과정에서 다시 또 다른 가중치와 곱해지고 편향이 더해지면, 입력이었던 원-핫 벡터들과 동일하게 V차원의 벡터를 얻습니다. 만약 입력 벡터의 차원이 7이었다면 여기서 나오는 벡터도 마찬가지입니다.\n",
    "\n",
    "출력층에서는 활성화 함수로 소프트맥스(softmax) 함수를 사용하는데, V차원의 벡터는 소프트맥스 함수를 지나면서 각 원소는 0과 1사이의 실수값을 가지며 총 합은 1이 되는 상태로 바뀝니다. 이렇게 나온 벡터를 NNLM의 예측값이라는 의미에서 $\\hat{y}$라고 합시다. 이를 식으로 표현하면 아래와 같습니다.\n",
    "\n",
    "**출력층:**\n",
    "\n",
    "<br>\n",
    "$$\n",
    "\\hat{y} = softmax(W_{y}h^{layer} + b_{y})\n",
    "$$\n",
    "<br>\n",
    "\n",
    "벡터 $\\hat{y}$의 각 차원 안에서의 값이 의미하는 것은 이와 같습니다. $\\hat{y}$의 j번째 인덱스가 가진 0과 1사이의 값은 j번째 단어가 다음 단어일 확률을 나타냅니다. 그리고 $\\hat{y}$는 실제값. 즉, 실제 정답에 해당되는 단어인 원-핫 벡터의 값에 가까워져야 합니다. 실제값에 해당되는 다음 단어를 y라고 했을 때, 이 두 벡터가 가까워지게 하기위해서 NNLM는 손실 함수로 cross-entropy 함수를 사용합니다. 그리고 역전파가 이루어지면서 가중치 행렬들이 학습되는데, 이 과정에서 임베딩 벡터값들도 학습이 됩니다.\n",
    "\n",
    "이번 예제에서는 7개의 단어만 사용했지만, 만약 충분한 훈련 데이터가 있다는 가정 하에 NNLM이 얻을 수 있는 이점은 무엇일까요? NNLM의 핵심은 충분한 양의 훈련 코퍼스를 위와 같은 과정으로 학습한다면 결과적으로 수많은 문장에서 유사한 목적으로 사용되는 단어들은 결국 유사한 임베딩 벡터값을 얻게되는 것에 있습니다. 이렇게 되면 훈련이 끝난 후 다음 단어를 예측 과정에서 훈련 코퍼스에서 없던 단어 시퀀스라고 하더라도 다음 단어를 선택할 수 있습니다.\n",
    "\n",
    "그리고 단어 간 유사도를 구할 수 있는 임베딩 벡터의 아이디어는 Word2Vec, FastText, GloVe 등으로 발전되어서 딥 러닝 모델에서는 필수적으로 사용되는 방법이 되었습니다. 임베딩 벡터에 대해서는 워드 임베딩 챕터에서 좀 더 자세히 다룹니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **4. NNLM의 이점과 한계**\n",
    "\n",
    "NNLM은 기존 n-gram 언어 모델의 한계를 몇 가지 개선하였지만 또한 여전히 가지는 문제점이 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) 기존 모델에서의 개선점**\n",
    "\n",
    "NNLM은 단어의 유사도를 단어를 표현하기 위해 밀집 벡터(dense vector)를 사용하므로서 단어의 유사도를 표현할 수 있었습니다. 그리고 이를 통해 희소 문제(sparsity problem)를 해결하였습니다. 밀집 벡터란 벡터의 원소들이 실수값을 가지면서, 원-핫 벡터보다 저차원을 가지는 벡터를 말합니다. 반면, 원-핫 벡터는 벡터의 원소값이 대부분이 0이란 의미에서 희소 벡터(sparse vector)라고 부릅니다. 더 자세한 내용은 워드 임베딩 챕터에서 다룹니다.\n",
    "\n",
    "또한 더 이상 모든 n-gram을 저장하지 않아도 된다는 점에서 n-gram 언어 모델보다 저장 공간의 이점을 가집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) 고정된 길이의 입력(Fixed-length input)**\n",
    "\n",
    "NNLM이 극복하지 못한 한계 또한 존재합니다. NNLM은 n-gram 언어 모델과 마찬가지로 다음 단어를 예측하기 위해 모든 이전 단어를 참고하는 것이 아니라, 정해진 n개의 단어만을 참고합니다. 이는 버려지는 단어들이 가진 문맥 정보는 참고할 수 없음을 의미합니다.\n",
    "\n",
    "훈련 코퍼스에 있는 각 문장의 길이는 전부 다를 수 있으므로, 이를 개선하기 위해서는 모델이 매번 다른 길이의 입력 시퀀스에 대해서도 처리할 수 있는 능력이 필요합니다. 피드 포워드 신경망으로 만든 언어 모델이 이를 할 수 없다면, 피드 포워드 신경망이 아닌 다른 신경망을 사용하면 됩니다. 다음 챕터에서 RNN(Recurrent Neural Network)을 학습하고, 그 이후에 RNN을 이용하여 만든 언어 모델인 RNN 언어 모델(Recurrent Neural Network Language Model, RNNLM)에 대해서 배웁니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# **순환 신경망(Recurrent Neural Network, RNN)**\n",
    "\n",
    "RNN(Recurrent Neural Network)은 시퀀스(Sequence) 모델입니다. 입력과 출력을 시퀀스 단위로 처리하는 모델입니다. 번역기를 생각해보면 입력은 번역하고자 하는 문장. 즉, 단어 시퀀스입니다. 출력에 해당되는 번역된 문장 또한 단어 시퀀스입니다. 이러한 시퀀스들을 처리하기 위해 고안된 모델들을 시퀀스 모델이라고 합니다. 그 중에서도 RNN은 딥 러닝에 있어 가장 기본적인 시퀀스 모델입니다.\n",
    "\n",
    "뒤에서 배우는 LSTM이나 GRU 또한 근본적으로 RNN에 속합니다. RNN을 이해하고 이를 통해 10챕터의 텍스트 분류, 11챕터의 태깅 작업, 12챕터의 기계 번역을 이해해해봅니다.\n",
    "\n",
    "- *용어는 비슷하지만 순환 신경망과 재귀 신경망(Recursive Neural Network)은 전혀 다른 개념입니다.*  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. 순환 신경망(Recurrent Neural Network, RNN)**\n",
    "\n",
    "지금까지 배운 신경망들은 전부 은닉층에서 활성화 함수를 지난 값은 오직 출력층 방향으로만 향했습니다. 이러한 신경망을 피드 포워드 신경망(Feed Forward Neural Network)이라고 합니다. 그런데 그렇지 않은 신경망들이 있습니다. RNN(Recurrent Neural Network) 또한 그 중 하나입니다. RNN은 은닉층의 노드에서 활성화 함수를 통해 나온 결과값을 출력층 방향으로도 보내면서, 다시 은닉층 노드의 다음 계산의 입력으로 보내는 특징을 갖고있습니다.\n",
    "\n",
    "![img](https://wikidocs.net/images/page/22886/rnn_image1_ver2.PNG)\n",
    "\n",
    "이를 그림으로 표현하면 위와 같습니다. x는 입력층의 입력 벡터, y는 출력층의 출력 벡터입니다. 실제로는 편향 b도 입력으로 존재할 수 있지만 앞으로의 그림에서는 생략합니다. RNN에서 은닉층에서 활성화 함수를 통해 결과를 내보내는 역할을 하는 노드를 셀(cell)이라고 합니다. 이 셀은 이전의 값을 기억하려고 하는 일종의 메모리 역할을 수행하므로 이를 **메모리 셀** 또는 **RNN 셀**이라고 표현합니다.\n",
    "\n",
    "은닉층의 메모리 셀은 각각의 시점(time-step)에서 바로 이전 시점에서의 은닉층의 메모리 셀에서 나온 값을 자신의 입력으로 사용하는 재귀적 활동을 하고 있습니다. 앞으로는 현재 시점을 변수 t로 표현하겠습니다. 이는 현재 시점 t에서의 메모리 셀이 갖고있는 값은 과거의 메모리 셀들의 값에 영향을 받은 것임을 의미합니다. 그렇다면 메모리 셀이 갖고 있는 이 값은 뭐라고 부를까요?\n",
    "\n",
    "메모리 셀이 출력층 방향으로 또는 다음 시점 t+1의 자신에게 보내는 값을 **은닉 상태(hidden state)**라고 합니다. 다시 말해 t 시점의 메모리 셀은 t-1 시점의 메모리 셀이 보낸 은닉 상태값을 t 시점의 은닉 상태 계산을 위한 입력값으로 사용합니다.\n",
    "\n",
    "![img](https://wikidocs.net/images/page/22886/rnn_image2_ver3.PNG)\n",
    "\n",
    "RNN을 표현할 때는 일반적으로 위의 그림에서 좌측과 같이 화살표로 사이클을 그려서 재귀 형태로 표현하기도 하지만, 우측과 같이 사이클을 그리는 화살표 대신 여러 시점으로 펼쳐서 표현하기도 합니다. 두 그림은 동일한 그림으로 단지 사이클을 그리는 화살표를 사용하여 표현하였느냐, 시점의 흐름에 따라서 표현하였느냐의 차이일 뿐 둘 다 동일한 RNN을 표현하고 있습니다.\n",
    "\n",
    "![img](https://wikidocs.net/images/page/22886/rnn_image3_ver2.PNG)\n",
    "\n",
    "RNN은 입력과 출력의 길이를 다르게 설계 할 수 있으므로 다양한 용도로 사용할 수 있습니다. 위 그림은 입력과 출력의 길이에 따라서 달라지는 RNN의 다양한 형태를 보여줍니다. 위 구조가 자연어 처리에서 어떻게 사용될 수 있는지 예를 들어봅시다. RNN 셀의 각 시점 별 입, 출력의 단위는 사용자가 정의하기 나름이지만 가장 보편적인 단위는 단어 벡터입니다.\n",
    "\n",
    "예를 들어 하나의 입력에 대해서 여러개의 출력(one-to-many)의 모델은 하나의 이미지 입력에 대해서 사진의 제목을 출력하는 이미지 캡셔닝(Image Captioning) 작업에 사용할 수 있습니다. 사진의 제목은 단어들의 나열이므로 시퀀스 출력입니다.\n",
    "\n",
    "![img](https://wikidocs.net/images/page/22886/rnn_image3.5.PNG)\n",
    "\n",
    "또한 단어 시퀀스에 대해서 하나의 출력(many-to-one)을 하는 모델은 입력 문서가 긍정적인지 부정적인지를 판별하는 감성 분류(sentiment classification), 또는 메일이 정상 메일인지 스팸 메일인지 판별하는 스팸 메일 분류(spam detection)에 사용할 수 있습니다. 위 그림은 RNN으로 스팸 메일을 분류할 때의 아키텍처를 보여줍니다. 이러한 예제들은 **10챕터에서 배우는 텍스트 분류**에서 배웁니다.\n",
    "\n",
    "![img](https://wikidocs.net/images/page/22886/rnn_image3.7.PNG)\n",
    "\n",
    "다 대 다(many-to-many)의 모델의 경우에는 입력 문장으로 부터 대답 문장을 출력하는 챗봇과 입력 문장으로부터 번역된 문장을 출력하는 번역기, 또는 **11챕터에서 배우는 개체명 인식이나 품사 태깅과 같은 작업** 또한 속합니다. 위 그림은 개체명 인식을 수행할 때의 RNN 아키텍처를 보여줍니다.\n",
    "\n",
    "이제 RNN에 대한 수식을 정의해보겠습니다.\n",
    "\n",
    "![img](https://wikidocs.net/images/page/22886/rnn_image4_ver2.PNG)\n",
    "\n",
    "현재 시점 t에서의 은닉 상태값을 $h_{t}$라고 정의하겠습니다. 은닉층의 메모리 셀은 $h_{t}$를 계산하기 위해서 총 두 개의 가중치를 갖게 됩니다. 하나는 입력층에서 입력값을 위한 가중치 $W_{x}$이고, 하나는 이전 시점 t-1의 은닉 상태값인 $h_{t-1}$을 위한 가중치 $W_{h}$입니다.\n",
    "\n",
    "이를 식으로 표현하면 다음과 같습니다.\n",
    "\n",
    "- **은닉층 :** $h_{t} = tanh(W_{x} x_{t} + W_{h}h_{t−1} + b)$\n",
    "\n",
    "- **출력층 :** $y_{t} = f(W_{y}h_{t} + b)$\n",
    "\n",
    "단, $f$는 비선형 활성화 함수 중 하나.\n",
    "\n",
    "RNN의 은닉층 연산을 벡터와 행렬 연산으로 이해할 수 있습니다. 자연어 처리에서 RNN의 입력 $x_{t}$는 대부분의 경우에서 단어 벡터로 간주할 수 있는데, 단어 벡터의 차원을 d라고 하고, 은닉 상태의 크기를 $D_{h}$라고 하였을 때 각 벡터와 행렬의 크기는 다음과 같습니다.\n",
    "\n",
    "- **$x_{t}$ :** $(d × 1)$\n",
    "- **$W_{x}$ :** $(D_{h} × d)$\n",
    "- **$W_{h}$ :** $(D_{h} × D_{h})$\n",
    "- **$h_{t-1}$ :** $(D_{h} × 1)$\n",
    "- **$b$ :** $(D_{h} × 1)$\n",
    "\n",
    "배치 크기가 1이고, $d$와 $(D_{h}$ 두 값 모두를 4로 가정하였을 때, RNN의 은닉층 연산을 그림으로 표현하면 아래와 같습니다.\n",
    "\n",
    "![img](https://wikidocs.net/images/page/22886/rnn_images4-5.PNG)\n",
    "\n",
    "이때 $h_{t}$를 계산하기 위한 활성화 함수로는 주로 하이퍼볼릭탄젠트 함수(tanh)가 사용되지만, ReLU로 바꿔 사용하는 시도도 있습니다.\n",
    "\n",
    "위의 식에서 각각의 가중치 $W_{x}$, $W_{h}$, $W_{y}$의 값은 모든 시점에서 값을 동일하게 공유합니다. 만약, 은닉층이 2개 이상일 경우에는 은닉층 2개의 가중치는 서로 다릅니다.\n",
    "\n",
    "출력층은 결과값인 $y_{t}$를 계산하기 위한 활성화 함수로는 상황에 따라 다를텐데, 예를 들어서 이진 분류를 해야하는 경우라면 시그모이드 함수를 사용할 수 있고 다양한 카테고리 중에서 선택해야하는 문제라면 소프트맥스 함수를 사용하게 될 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **2. 케라스(Keras)로 RNN 구현하기**\n",
    "\n",
    "케라스로 RNN 층을 추가하는 코드는 다음과 같습니다.\n",
    "\n",
    "```python\n",
    "# RNN 층을 추가하는 코드.\n",
    "model.add(SimpleRNN(hidden_size)) # 가장 간단한 형태\n",
    "```\n",
    "\n",
    "인자를 사용할 때를 보겠습니다.\n",
    "\n",
    "```python\n",
    "# 추가 인자를 사용할 때\n",
    "model.add(SimpleRNN(hidden_size, input_shape=(timesteps, input_dim)))\n",
    "\n",
    "# 다른 표기\n",
    "model.add(SimpleRNN(hidden_size, input_length=M, input_dim=N)) # 단, M과 N은 정수\n",
    "```\n",
    "\n",
    "- **hidden_size** = 은닉 상태의 크기를 정의. 메모리 셀이 다음 시점의 메모리 셀과 출력층으로 보내는 값의 크기(output_dim)와도 동일. RNN의 용량(capacity)을 늘린다고 보면 되며, 중소형 모델의 경우 보통 128, 256, 512, 1024 등의 값을 가진다.\n",
    "- **timesteps** = 입력 시퀀스의 길이(input_length)라고 표현하기도 함. 시점의 수.\n",
    "- **input_dim** = 입력의 크기.\n",
    "\n",
    "![img](https://wikidocs.net/images/page/22886/rnn_image6between7.PNG)\n",
    "\n",
    "RNN 층은 (batch_size, timesteps, input_dim) 크기의 3D 텐서를 입력으로 받습니다. batch_size는 한 번에 학습하는 데이터의 개수를 말합니다.\n",
    "\n",
    "- <u>*훈련 데이터를 여러개 묶어서 한 꺼번에 입력으로 사용하는 것을 배치(Batch)라고 합니다.*</u>\n",
    "\n",
    " ***(여기서부터는 텐서의 개념을 반드시 이해해야 하므로 벡터와 행렬 연산 챕터의 텐서 설명 부분을 참고하시기 바랍니다.)***\n",
    "\n",
    "다만, 이러한 표현은 사람이나 문헌에 따라서, 또는 풀고자 하는 문제에 따라서 종종 다르게 기재되는데 위의 그림은 문제와 상황에 따라서 다르게 표현되는 입력 3D 텐서의 대표적인 표현들을 보여줍니다.\n",
    "\n",
    "헷갈리지 말아야할 점은 위의 코드는 출력층까지 포함한 하나의 완성된 인공 신경망 코드가 아니라 은닉층. 즉, RNN 층에 대한 코드라는 점입니다. 해당 코드가 리턴하는 결과값은 출력층의 결과가 아니라 하나의 은닉 상태 또는 정의하기에 따라 다수의 은닉 상태 입니다. 아래의 그림은 앞서 배운 출력층을 포함한 완성된 인공 신경망 그림과 은닉층까지만 표현한 그림의 차이를 보여줍니다.\n",
    "\n",
    "![img](https://wikidocs.net/images/page/22886/rnn_image7_ver2.PNG)\n",
    "\n",
    "그렇다면 RNN 층은 위에서 설명한 입력 3D 텐서를 입력받아서 어떻게 은닉 상태를 출력할까요? RNN 층은 사용자의 설정에 따라 두 가지 종류의 출력을 내보냅니다. 메모리 셀의 최종 시점의 은닉 상태만을 리턴하고자 한다면 (batch_size, output_dim) 크기의 2D 텐서를 리턴합니다. 하지만, 메모리 셀의 각 시점(time-step)의 은닉 상태값들을 모아서 전체 시퀀스를 리턴하고자 한다면 (batch_size, timesteps, output_dim) 크기의 3D 텐서를 리턴합니다. 이는 RNN 층의 return_sequences 매개 변수에 True를 설정하여 설정이 가능합니다. (output_dim은 앞서 코드에서 정의한 hidden_size의 값으로 설정됩니다.)\n",
    "\n",
    "![img](https://wikidocs.net/images/page/22886/rnn_image8_ver2.PNG)\n",
    "\n",
    "위의 그림은 timesteps=3일 때, return_sequences = True를 설정했을 때와 그렇지 않았을 때 어떤 차이가 있는지를 보여줍니다. return_sequences=True를 선택하면 메모리 셀이 모든 시점(time-step)에 대해서 은닉 상태값을 출력하며, 별도 기재하지 않거나 return_sequences=False로 선택할 경우에는 메모리 셀은 하나의 은닉 상태값만을 출력합니다. 그리고 이 하나의 값은 마지막 시점(time-step)의 메모리 셀의 은닉 상태값입니다.\n",
    "\n",
    "마지막 은닉 상태만 전달하도록 하면 many-to-one 문제를 풀 수 있고, 모든 시점의 은닉 상태를 전달하도록 하면, 다음층에 은닉층이 하나 더 있는 경우이거나 many-to-many 문제를 풀 수 있습니다.\n",
    "\n",
    "뒤에서 배우는 LSTM이나 GRU도 내부 메커니즘은 다르지만 model.add()를 통해서 층을 추가하는 코드는 사실상 SimpleRNN 코드와 같은 형태를 가집니다. 실습을 통해 모델 내부적으로 출력 결과를 어떻게 정의하는지 보면서 RNN을 이해해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_2 (SimpleRNN)     (None, 3)                 42        \n",
      "=================================================================\n",
      "Total params: 42\n",
      "Trainable params: 42\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# model.add(SimpleRNN(3, input_length=2, input_dim=10))와 동일함.\n",
    "model.add(SimpleRNN(3, input_shape=(2,10)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "출력값이 (batch_size, output_dim) 크기의 2D 텐서일 때, output_dim은 hidden_size의 값인 3입니다. 이 경우 batch_size를 현 단계에서는 알 수 없으므로 (None, 3)이 됩니다. 이번에는 batch_size를 미리 정의해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_3 (SimpleRNN)     (8, 3)                    42        \n",
      "=================================================================\n",
      "Total params: 42\n",
      "Trainable params: 42\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(3, batch_input_shape=(8, 2, 10)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch_size를 8로 기재하자, 출력의 크기가 (8, 3)이 된 것을 볼 수 있습니다. 이제 return_sequences 매개 변수에 True를 기재하여 출력값으로 (batch_size, timesteps, output_dim) 크기의 3D 텐서를 리턴하도록 모델을 만들어 보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_4 (SimpleRNN)     (8, 2, 3)                 42        \n",
      "=================================================================\n",
      "Total params: 42\n",
      "Trainable params: 42\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(3, batch_input_shape=(8, 2, 10), return_sequences=True))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "출력의 크기가 (8, 2, 3)이 된 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **3. 파이썬으로 RNN 구현하기**\n",
    "\n",
    "직접 Numpy로 RNN 층을 구현해보겠습니다. 앞서 메모리 셀에서 은닉 상태를 계산하는 식을 다음과 같이 정의하였습니다.\n",
    "\n",
    "<br>\n",
    "$$\n",
    "h_{t} = tanh(W_{x}X_{t} + W_{h}h_{t−1} + b)\n",
    "$$\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "실제 구현에 앞서 간단히 의사 코드(pseudocode)를 작성해보겠습니다.\n",
    "\n",
    "```python\n",
    "# 아래의 코드는 의사 코드(pseudocode)로 실제 동작하는 코드가 아님. \n",
    "\n",
    "hidden_state_t = 0 # 초기 은닉 상태를 0(벡터)로 초기화\n",
    "for input_t in input_length: # 각 시점마다 입력을 받는다.\n",
    "    output_t = tanh(input_t, hidden_state_t) # 각 시점에 대해서 입력과 은닉 상태를 가지고 연산\n",
    "    hidden_state_t = output_t # 계산 결과는 현재 시점의 은닉 상태가 된다.\n",
    "```\n",
    "\n",
    "우선 t 시점의 은닉 상태를 hidden_state_t라는 변수로 선언하였고, 입력 데이터의 길이를 input_length로 선언하였습니다. 이 경우, 입력 데이터의 길이는 곧 총 시점의 수(timesteps)가 됩니다. 그리고 t 시점의 입력값을 input_t로 선언하였습니다. 각 메모리 셀은 각 시점마다 input_t와 hidden_sate_t(이전 상태의 은닉 상태)를 입력으로 활성화 함수인 하이퍼볼릭탄젠트 함수를 통해 현 시점의 hidden_state_t를 계산합니다.\n",
    "\n",
    "의사 코드를 통해 간단히 개념 정립을 해보았습니다. 이제 RNN 층을 실제 동작되는 코드로 구현해보겠습니다. 아래의 코드는 이해를 돕기 위해 (timesteps, input_dim) 크기의 2D 텐서를 입력으로 받았다고 가정하였으나, 실제로 케라스에서는 (batch_size, timesteps, input_dim)의 크기의 3D 텐서를 입력으로 받는 것을 기억합시다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "timesteps = 10 # 시점의 수. NLP에서는 보통 문장의 길이가 된다.\n",
    "input_dim = 4 # 입력의 차원. NLP에서는 보통 단어 벡터의 차원이 된다.\n",
    "hidden_size = 8 # 은닉 상태의 크기. 메모리 셀의 용량이다.\n",
    "\n",
    "inputs = np.random.random((timesteps, input_dim)) # 입력에 해당되는 2D 텐서\n",
    "\n",
    "hidden_state_t = np.zeros((hidden_size,)) # 초기 은닉 상태는 0(벡터)로 초기화\n",
    "# 은닉 상태의 크기 hidden_size로 은닉 상태를 만듬."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우선 시점, 입력의 차원, 은닉 상태의 크기, 그리고 초기 은닉 상태를 정의하였습니다. 현재 초기 은닉 상태는 0의 값을 가지는 벡터로 초기화가 된 상태입니다. 초기 은닉 상태를 출력해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(hidden_state_t) # 8의 크기를 가지는 은닉 상태. 현재는 초기 은닉 상태로 모든 차원이 0의 값을 가짐."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "은닉 상태의 크기를 8로 정의하였으므로 8의 차원을 가지는 0의 값으로 구성된 벡터가 출력됩니다. 이제 가중치와 편향을 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wx = np.random.random((hidden_size, input_dim))  # (8, 4)크기의 2D 텐서 생성. 입력에 대한 가중치.\n",
    "Wh = np.random.random((hidden_size, hidden_size)) # (8, 8)크기의 2D 텐서 생성. 은닉 상태에 대한 가중치.\n",
    "b = np.random.random((hidden_size,)) # (8,)크기의 1D 텐서 생성. 이 값은 편향(bias)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가중치와 편향을 각 크기에 맞게 정의하였습니다. 가중치와 편향의 크기를 출력해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 4)\n",
      "(8, 8)\n",
      "(8,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(Wx))\n",
    "print(np.shape(Wh))\n",
    "print(np.shape(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 가중치와 편향의 크기는 다음과 같습니다. Wx는 (은닉 상태의 크기 × 입력의 차원), Wh는 (은닉 상태의 크기 × 은닉 상태의 크기), b는 (은닉 상태의 크기)의 크기를 가집니다. 이제 모든 시점의 은닉 상태를 출력한다고 가정하고, RNN 층을 동작시켜봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 8)\n",
      "(2, 8)\n",
      "(3, 8)\n",
      "(4, 8)\n",
      "(5, 8)\n",
      "(6, 8)\n",
      "(7, 8)\n",
      "(8, 8)\n",
      "(9, 8)\n",
      "(10, 8)\n",
      "[[0.88505538 0.92703253 0.94999511 0.76897715 0.93213402 0.91372972\n",
      "  0.90491975 0.8741577 ]\n",
      " [0.99873212 0.99990111 0.99980612 0.9997828  0.99994041 0.99964563\n",
      "  0.9989139  0.99988989]\n",
      " [0.99930742 0.99991517 0.99991479 0.99995406 0.99997588 0.99971762\n",
      "  0.99922963 0.99992744]\n",
      " [0.99790591 0.999856   0.99959081 0.99988047 0.99992903 0.99940921\n",
      "  0.99755236 0.99984522]\n",
      " [0.99929747 0.99996876 0.99987363 0.99997701 0.99997948 0.99978032\n",
      "  0.99959164 0.99995188]\n",
      " [0.99880225 0.99998149 0.99988595 0.99996771 0.99997229 0.99984148\n",
      "  0.99972931 0.99996943]\n",
      " [0.99913193 0.99997165 0.99987357 0.99995785 0.99997741 0.99980831\n",
      "  0.99961093 0.99996153]\n",
      " [0.99933226 0.99997645 0.99989858 0.99993492 0.99998395 0.99985243\n",
      "  0.99969532 0.99997344]\n",
      " [0.99957503 0.99995832 0.99990543 0.9999648  0.99998673 0.99979247\n",
      "  0.99955533 0.99995514]\n",
      " [0.99868649 0.99997599 0.99980808 0.99997282 0.99996659 0.99977434\n",
      "  0.99958693 0.99995335]]\n"
     ]
    }
   ],
   "source": [
    "total_hidden_states = []\n",
    "\n",
    "# 메모리 셀 동작\n",
    "for input_t in inputs: # 각 시점에 따라서 입력값이 입력됨.\n",
    "  output_t = np.tanh(np.dot(Wx,input_t) + np.dot(Wh,hidden_state_t) + b) # Wx * Xt + Wh * Ht-1 + b(bias)\n",
    "  total_hidden_states.append(list(output_t)) # 각 시점의 은닉 상태의 값을 계속해서 축적\n",
    "  print(np.shape(total_hidden_states)) # 각 시점 t별 메모리 셀의 출력의 크기는 (timestep, output_dim)\n",
    "  hidden_state_t = output_t\n",
    "\n",
    "total_hidden_states = np.stack(total_hidden_states, axis = 0) \n",
    "# 출력 시 값을 깔끔하게 해준다.\n",
    "\n",
    "print(total_hidden_states) # (timesteps, output_dim)의 크기. 이 경우 (10, 8)의 크기를 가지는 메모리 셀의 2D 텐서를 출력."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **4. BPTT(Backpropagation through time, BPTT)**\n",
    "\n",
    "RNN도 다른 인공 신경망과 마찬가지로 역전파를 통해서 학습을 진행합니다. 피드 포워드 신경망의 역전파와 다른 점이 있다면, RNN은 전체 시점에 대해서 네트워크를 펼친 다음에 역전파를 사용하며 모든 시점에 대해서 가중치를 공유하고 있다는 점입니다. RNN의 이러한 역전파 과정을 BPTT(Backpropagation through time)이라고 부릅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. 양방향 순환 신경망(Bidirectional Recurrent Neural Network)**\n",
    "\n",
    "양방향 순환 신경망은 시점 t에서의 출력값을 예측할 때 이전 시점의 데이터뿐만 아니라, 이후 데이터로도 예측할 수 있다는 아이디어에 기반합니다.\n",
    "\n",
    "영어 빈칸 채우기 문제에 비유하여 보겠습니다.\n",
    "\n",
    "```python\n",
    "# Exercise is very effective at [          ] belly fat.\n",
    "\n",
    "# 1) reducing\n",
    "# 2) increasing\n",
    "# 3) multiplying\n",
    "```\n",
    "\n",
    "'운동은 복부 지방을 [ ] 효과적이다'라는 영어 문장이고, 정답은 reducing(줄이는 것)입니다. 그런데 위의 영어 빈 칸 채우기 문제를 잘 생각해보면 정답을 찾기 위해서는 이전에 나온 단어들만으로는 부족합니다. 목적어인 belly fat(복부 지방)를 모르는 상태라면 정답을 결정하기가 어렵습니다.\n",
    "\n",
    "즉, RNN이 과거 시점(time-step)의 데이터들을 참고해서, 찾고자하는 정답을 예측하지만 실제 문제에서는 과거 시점의 데이터만 고려하는 것이 아니라 향후 시점의 데이터에 힌트가 있는 경우도 많습니다. 그래서 이전 시점의 데이터뿐만 아니라, 이후 시점의 데이터도 힌트로 활용하기 위해서 고안된 것이 양방향 RNN입니다.\n",
    "\n",
    "![img](https://wikidocs.net/images/page/22886/rnn_image5_ver2.PNG)\n",
    "\n",
    "양방향 RNN은 하나의 출력값을 예측하기 위해 기본적으로 두 개의 메모리 셀을 사용합니다. 첫번째 메모리 셀은 앞에서 배운 것처럼 **앞 시점의 은닉 상태(Forward States)**를 전달받아 현재의 은닉 상태를 계산합니다. 두번째 메모리 셀은 앞에서 배운 것과는 다릅니다. 앞 시점의 은닉 상태가 아니라 **뒤 시점의 은닉 상태(Backward States)**를 전달 받아 현재의 은닉 상태를 계산합니다. 그리고 이 두 개의 값 모두가 하나의 출력값을 예측하기 위해 사용됩니다.\n",
    "\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(SimpleRNN(hidden_size, return_sequences = True), input_shape=(timesteps, input_dim)))\n",
    "```\n",
    "\n",
    "앞서 RNN도 다수의 은닉층을 가질 수 있다고 언급한 바 있습니다. 아래의 그림은 양방향 순환 신경망에서 은닉층이 1개 더 추가되어 은닉층이 2개인 깊은(Deep) 양방향 순환 신경망의 모습을 보여줍니다.\n",
    "\n",
    "![img](https://wikidocs.net/images/page/22886/rnn_image6_ver3.PNG)\n",
    "\n",
    "다른 인공 신경망 모델들도 마찬가지이지만, 은닉층을 무조건 추가한다고 해서 모델의 성능이 좋아지는 것은 아닙니다. 은닉층을 추가하면, 학습할 수 있는 양이 많아지지만 또한 반대로 훈련 데이터 또한 그만큼 많이 필요합니다. 아래의 코드는 은닉층이 4개인 경우를 보여줍니다.\n",
    "\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(SimpleRNN(hidden_size, return_sequences = True), input_shape=(timesteps, input_dim)))\n",
    "model.add(Bidirectional(SimpleRNN(hidden_size, return_sequences = True)))\n",
    "model.add(Bidirectional(SimpleRNN(hidden_size, return_sequences = True)))\n",
    "model.add(Bidirectional(SimpleRNN(hidden_size, return_sequences = False)))\n",
    "```\n",
    "\n",
    "지금은 깊은 양방향 RNN에 대해서 설명하고 있지만, 물론 단방향 RNN에 대해서도 은닉층을 추가하여 깊은 단방향 RNN을 설계하는 것도 가능합니다. 예를 들어 앞서 배운 단방향 RNN으로 은닉층을 추가하는 경우 코드는 아래와 같습니다.\n",
    "\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(hidden_size, return_sequences = True))\n",
    "model.add(SimpleRNN(hidden_size, return_sequences = False))\n",
    "```\n",
    "\n",
    "양방향 RNN은 태깅 작업 챕터에서 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
