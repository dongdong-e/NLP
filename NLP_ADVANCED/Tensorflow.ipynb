{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **텐서플로(tensorflow)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **tf.keras.layer.Dense**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **아래는 입력 값에 대해 활성화 함수로 시그모이드 함수를 사용하고, 출력 값으로 10개의 값을 출력하는 완전 연결 계층(Fully Connected Layer) 정의한 것이다.**<br>\n",
    "    * 시그모이드 함수 참고 사이트: https://icim.nims.re.kr/post/easyMath/64\n",
    "\n",
    "* **완전 연결 계층(Fully Connected Layer)란? https://kolikim.tistory.com/53**\n",
    "    * 완전 연결 신경망이란, 인접하는 계층의 모든 뉴런과 결합되어 있는 신경망을 말한다. 입력 데이터와 가중치가 1대 1로 대응하는 것을 완전 연결(Fully-Connected)이라고 하며, 행렬의 내적(Affine)으로 표현된다. 이 완전 계층의 문제점은 바로 데이터의 형상이 무시된다는 것이다. 입력 데이터가 다차원의 형상일 때, 완전 연결 계층에 입력해주기 위해서는 이 다차원 데이터를 1차원으로 평탄화해준 후에 입력하여야만 한다.\n",
    "    * 가장 흔한 다차원 데이터인 이미지를 생각해보면, 이미지 하나는 2차원의 픽셀 배열에 RGB의 채널이 합쳐져 3차원을 이루고 있다. 이 RGB의 각 채널은 서로 밀접하게 관련되어 있고, 픽셀 간의 거리에 따라 또한 관련되어 있는 등 3차원 속에서 의미를 갖는 패턴이 숨어 있다. 그러나 완전 연결 계층은 형상을 무시하고 모든 입력 데이터를 동일 차원으로 취급하기에 형상에 담긴 정보를 살릴 수 없다.\n",
    "---\n",
    "* **Dense 함수 options**\n",
    "    * **y =f(Wx + b)**\n",
    "        1. units: 출력 값의 크기, Integer 혹은 Long 형태\n",
    "        2. ativation: 활성화 함수\n",
    "        3. use_bias: 편향(b)을 사용할지 여부, Boolean 값 형태\n",
    "        4. kernel_initializer: 가중치(W) 초기화 함수\n",
    "        5. bias_initializer: 편향 초기화 함수\n",
    "        6. kernel_regularizer: 가중치 정규화 방법\n",
    "        7. bias_regularizer: 편향 정규화 방법\n",
    "        8. kernel_constraint: Optimizer에 의해 업데이트 된 이후에 가중치에 적용되는 부가적인 제약 함수 (예시: norm constraint, value constraint)\n",
    "        9. bias_constraint: Optimizer에 의해 업데이트 된 이후에 편향에 적용되는 부가적인 제약 함수 (예시: norm contraint, value constraint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = (20, 1)\n",
    "\n",
    "input = tf.placeholder(tf.float32, shape = INPUT_SIZE)\n",
    "output = tf.keras.layers.Dense(units = 10, activation = tf.nn.sigmoid)(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **아래는 10개의 노드를 가지는 은닉층이 있고 최종 출력 값은 2개의 노드가 있는 신경망 구조를 정의한 것이다. 객체를 두 개 생성하여 신경망을 만들 수 있다.**\n",
    "\n",
    "* **은닉층**\n",
    "참고사이트: https://blog.lgcns.com/1359"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = (20, 1)\n",
    "\n",
    "input = tf.placeholder(tf.float32, shape = INPUT_SIZE)\n",
    "hidden = tf.keras.layers.Dense(units = 10, activation = tf.nn.sigmoid)(input)\n",
    "output = tf.keras.layers.Dense(units = 2, activation = tf.nn.sigmoid)(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **tf.keras.layers.Dropout**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 신경망 모델을 만들 때 생기는 여러 문제점 중 대표적인 문제점은 **과적합(Overfitting)** 이다. 과적합 문제는 **정규화(Regularization)** 방법을 사용하여 해결하는데, 그중 가장 대표적인 방법이 **드롭아웃(Dropout)** 이다.\n",
    "\n",
    "* 텐서플로는 드롭아웃을 쉽게 모델에 적용할 수 있게 간단한 모듈을 제공하는데, 이 모듈을 이용하면 특정 keras.layers의 입력 값에 드롭아웃을 적용할 수 있다. 사용법은 위의 dense 층을 만드는 방법과 유사하게 Dropout 객체를 생성해서 사용할 수 있다.\n",
    "---\n",
    "* **Drop 함수 options**\n",
    "    1. rate: 드롭아웃을 적용할 확률을 지정한다. 확률 값이므로 0 ~ 1 사이의 값을 받는다. 예를 들어 dropout = 0.2로 지정하면 전체 입력 값 중에서 20%를 0으로 만든다.\n",
    "    2. noise_shape: 정수형의 1D-tensor 값을 받는다. 여기서 받은 값은 shape을 뜻하는데, 이 값을 지정함으로써 특정 값만 드롭아웃을 적용할 수 있다. 예를 들면, 입력값이 이미지일 때 noise_shape을 지정하면 특정 채널에만 드롭아웃을 적용할 수 있다.\n",
    "    3. seed: 드롭아웃의 경우 지정된 확률 값을 바탕으로 무작위로 드롭아웃을 적용하는데, 이때 임의의 선택을 위한 시드값을 의미한다. seed 값은 정수형이며, 같은 seed 값을 가지는 드롭아웃의 경우 동일한 드롭아웃 결과를 만든다.\n",
    "---\n",
    "* 드롭아웃은 학습 데이터에 과적합되는 상황을 방지하기 위해 학습 시 특정 황률로 노드들의 값을 0으로 만든다. 그리고 이러한 과정은 학습할 때만 적용되고 예측 혹은 테스트할 때는 적용되지 않아야 한다. 케라스의 드롭아웃을 사용할 경우 이러한 부분이 자동으로 적용된다. 드롭아웃을 적용하는 방법은 아래와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = (20, 1)\n",
    "\n",
    "input = tf.placeholder(tf.float32, shape = INPUT_SIZE)\n",
    "dropout = tf.keras.layers.Dropout(rate = 0.5)(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 텐서플로에서 드롭아웃은 tf.keras.layers뿐만 아니라 tf.nn 모듈에도 있는데, 두 모듈의 차이점은 tf.keras.layers.dropout의 경우 확률을 0.2로 지정했을 때 노드의 20%를 0으로 만드는 데 비해 tf.nn.dropout의 경우 확률을 0.2로 지정했을 때 80%를 0으로 만든다는 차이점이 있다.\n",
    "\n",
    "* 드롭아웃을 적용하려는 층의 노드르 객체에 적용하면 된다. 아래 코드의 경우 입력 값에 드롭아웃을 적용한 후 Dense 층을 지나도록 작성했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = (20, 1)\n",
    "\n",
    "input = tf.placeholder(tf.float32, shape = INPUT_SIZE)\n",
    "dropout = tf.keras.layers.Dropout(rate = 0.2)(input)\n",
    "hidden = tf.keras.layers.Dense(units = 10, activation = tf.nn.sigmoid)(dropout)\n",
    "output = tf.keras.layers.Dense(units = 2, activation = tf.nn.sigmoid)(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **tf.keras.layers.Conv1D**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **합성곱이란? http://ppaktion.maru.net/702**\n",
    "    * 콘볼루션은 하나의 신호로 다른 신호를 번지게 하는 것이다. 연필로 종이에 찍은 점을 지우개로 가볍게 문지르면 번져난다. 연필로 찍은 점과 지우개의 콘볼루션이다. 이런 번짐 효과는 포토샵에서 블러 툴을 쓰는 것과도 같다. 이미지 프로세싱에서 필터링을 할 때 어떤 모양의 함수로 콘볼루션을 하느냐에 따라 다양한 출력을 얻는다. 광학에서 초점 밖의 흐릿한 상 역시 바늘구멍과 물체에서 나온 빛의 콘볼루션이다. \n",
    "    * 시간 시스템에서 입력값과 시스템 응답 함수의 콘볼루션으로 출력 값을 얻는다. 결국 같은 것이지만 이미지에서 가로 축은 공간이고 시간 시스템에서는 시간이라는 것이 다르다. 소리 신호가 방에서 반사되어서 울림이 생기는 것도 원래 신호와 방이라는 시스템 응답의 콘볼루션으로 나타낼 수 있다. 델타 함수와의 콘볼루션은 곱하기가 되기 때문에 시스템의 응답이 델타 함수라면 선형 시스템이라고 할 수 있다.\n",
    "    \n",
    "* 텐서플로의 합성곱 연산은 Conv1D, Conv2D, Conv3D로 나눠지는데, 어떤 차이가 있는지 알아보겠다. 우리가 흔히 알고 있는 기본적인 이미지에 적용하는 합성곱 방식은 Conv2D다. 합성곱은 일반적으로 두 가지 기준으로 구분할 수 있다. 바로 합성곱이 진행되는 방향과 합성곱 겨롸로 나오는 출력값이다. 이 두가지를 기준으로 비교한 결과는 다음과 같다.\n",
    "    * Conv1D: 한 방향(가로) / 1-D Array(vector)\n",
    "    * Conv2D: 두 방향(가로, 세로) / 2-D Array(matrix)\n",
    "    * Conv3D: 세 방향(가로, 세로, 높이) / 3-D Array(tensor)\n",
    "* 그러나 출력값의 경우 실제 합성곱 출력값과 동일하진 않다.배치 크기와 합성곱이 적용되는 필터의 개수도 고려해야 하기 때문에 출력값이 위와 동일하게 나오지 않는 것이다. 위의 경우는 단순히 배치의 경우는 고려하지 않고, 합성곱 필터를 하나만 적용했을 때라고 생각하면 된다.\n",
    "---\n",
    "* **합성곱 함수 options**\n",
    "    * 합성곱도 필터의 크기, 필터의 개수, 스트라이드 값 등으로 객체를 생성할 때 인자로 설정할 수 있다. 구조는 몇 가지를 제외하고 이전에 알아본 Dense와 비슷하다. 다른 점은 합성곱 연산을 수행할 필터와 관련된 부분이다. 그리고 합성곱은 기본적으로 필터의 크기를 필요로 하는데, 이 경우 Conv1D는 필터의 높이(high)는 필요하지 않다. Conv1D의 필터는 입력값의 차원수와 높이가 동일하게 연산되기 때문에 필터의 가로 길이만 설정하면 된다. 즉, 필터의 가로에 적용되는 kernel_size만 설정하면 된다. 그리고 총 몇 개의 필터를 사용할지를 filters 인자를 통해 정해야 한다.\n",
    "    * 예를 들어 (5, 10) 형태의 입려값에 필터의 크기인 kernel_size를 2로 설정하고 필터의 개수를 10으로 지정할 경우 출력값의 형태는 (1, 4, 10)이 된다. 그리고 패딩을 사용해 입력값과 출력값의 가로 크기를 똑같이 만들고 싶다면, padding = \"same\"을 지정하면 입력과 출력의 가로 값이 같아진다.\n",
    "\n",
    "1. filters: 필터의 개수로서, 정수형으로 지정한다. 출력의 차원수를 나타낸다.\n",
    "2. kernel_size: 필터의 크기로서, 정수 혹은 정수의 리스트, 튜플 형태로 지정한다. 합성곱이 적용되는 윈도우(window)의 길이를 나타낸다. \n",
    "3. strides: 적용할 스트라이드의 값으로서 정수 혹은 정수의 리스트, 튜플 형태로 지정한다. 1이 아닌 값을 지정할 경우 dilation_rate는 1 이외의 값을 지정하지 못한다.\n",
    "4. padding: 패딩 방법을 정한다. \"VALID\" 또는 \"SAME\"을 지정할 수 있다.\n",
    "5. data_format: 데이터의 표현 방법을 선택한다. \"channel_last\" 혹은 \"channel_first\"를 지정할 수 있다. last의 경우 데이터는 (batch, length, channels) 형태여야 하고, channel_first의 경우 데이터는 (batch, channels, length) 형태여야 한다.\n",
    "6. dilation_rate: dilation 합성곱 사용 시 적용할 dilation 값으로 정수 혹은 정수의 리스트, 튜플 형태로 지정한다. 1이 아닌 값을 지정하면 strides 값으로 1 이외의 값을 지정하지 못한다.\n",
    "7. activation: 활성화 함수\n",
    "8. use_bias: 편향을 사용할지 여부, Boolean 값 형태\n",
    "9. kernel_initializer: 가중치 초기화 함수\n",
    "10. bias_initializer: 편향 초기화 함수\n",
    "11. kernel_regularizer: 가중치 정규화 방법\n",
    "12. bias_regularizer: 편향 정규화 방법\n",
    "13. activity_regularizer: 출력값 정규화 방법\n",
    "14. kernel_constraint: Optimizer에 의해 업데이트 된 이후에 가중치에 적용되는 부가적인 제약 함수 (예시: norm constraint, value constraint)\n",
    "15. bias_constraint: Optimizer에 의해 업데이트 된 이후에 편향에 적용되는 부가적인 제약 함수 (예시: norm contraint, value constraint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv1D의 기본적인 사용법\n",
    "INPUT_SIZE = (1, 28, 28)\n",
    "\n",
    "input = tf.placeholder(tf.float32, shape = INPUT_SIZE)\n",
    "conv = tf.keras.layers.Conv1D(\n",
    "    filters = 10,\n",
    "    kernel_size = 3,\n",
    "    padding = \"same\",\n",
    "    activation = tf.nn.relu)(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 드롭아웃을 적용한 Conv1D 사용법\n",
    "INPUT_SIZE = (1, 28, 28)\n",
    "is_training = True\n",
    "\n",
    "input = tf.placeholder(tf.float32, shape = INPUT_SIZE)\n",
    "dropout = tf.keras.layers.Dropout(rate = 0.2)(input)\n",
    "conv = tf.keras.layers.Conv1D(\n",
    "    filters = 10,\n",
    "    kernel_size = 3,\n",
    "    padding = \"same\",\n",
    "    activation = tf.nn.relu)(dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **tf.keras.layers.MaxPool1D**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 합성곱 신경망과 함께 쓰이는 기법 중 하나는 **풀링**이다. 보통 피처 맵(feature map)의 크기를 줄이거나 주요한 특징을 뽑아내기 위해 합성곱 이후에 적용되는 기법이다.\n",
    "* 풀링에는 주로 두 가지 풀링 기법이 사용된다.\n",
    "    1. 맥스 풀링(Max-pooling): 피처 맵에 대해 최댓값만을 뽑아내는 방식\n",
    "    2. 평균 풀링(Average-poolig): 피처 맵에 대해 전체 값들을 평균한 값을 뽑는 방식\n",
    "---\n",
    "* 맥스 풀링도 합성곱과 같이 세 가지 형태로 모델이 나뉘어있다. MaxPool1D, MaxPool2D, MaxPool3D로 나뉘는데 합성곱과 똑같은 원리다. 자연어 처리에 주로 사용되는 합성곱과 동일하게 MaxPool1D를 주로 사용하는데 한 방향으로만 풀링이 진행된다.\n",
    "    1. pool_size: 풀링을 적용할 필터의 크기를 뜻한다. 정수를 받는다.\n",
    "    2. strides: 적용할 스트라이드의 값, 정수 혹은 None 값을 받는다.\n",
    "    3. padding: 패딩 방법을 지정한다. \"valid\" 또는 \"same\"을 지정할 수 있다.\n",
    "    4. data_format: 데이터의 표현 방법을 선택한다. \"channel_last\" 혹은 \"channel_first\"를 지정할 수 있다. last의 경우 데이터는 (batch, length, channels) 형태여야 하고, channel_first의 경우 데이터는 (batch, channels, length) 형태여야 한다.\n",
    "---\n",
    "* 아래는 입력값이 합성곱과 맥스 풀링을 사용한 후 완전 연결 계층을 통해 최종 출력값이 나오는 구조를 만든 내용이다. 그리고 입력값에는 드롭아웃을 적용했다. 맥스 풀링 결과값을 완전 연결 계층으로 연결하기 위해서는 행렬이었던 것을 벡터로 만들어야 한다. 이때 **tf.keras.layers.Flattent**을 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = (1, 28, 28)\n",
    "\n",
    "input = tf.placeholder(tf.float32, shape = INPUT_SIZE)\n",
    "dropout = tf.keras.layers.Dropout(rate = 0.2)(input)\n",
    "conv = tf.keras.layers.Conv1D(\n",
    "    filters = 10,\n",
    "    kernel_size = 3,\n",
    "    padding = \"same\",\n",
    "    activation = tf.nn.relu)(dropout)\n",
    "\n",
    "max_pool = tf.keras.layers.MaxPool1D(pool_size = 3, padding = \"same\")(conv)\n",
    "flatten = tf.keras.layers.Flatten()(max_pool)\n",
    "\n",
    "hidden = tf.keras.layers.Dense(units = 50, activation = tf.nn.relu)(flatten)\n",
    "output = tf.keras.layers.Dense(units = 10, activation = tf.nn.softmax)(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **tf.data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 기존의 텐서플로에서 데ㅐ이터를 처리하는 방식은 tf.placeholder와 tf.feed_dict를 활용해 모델에 값을 전달하는 방식이었지만 이는 데이터 셔플, 반복, 배치 설정 등과 같은 기능들을 모두 직접 구현해야 하고, 최적화돼 있지 않기 때문에 여러모로 신경 써야 할 부분이 많다. 이를 해결하기 위해 새롭게 추가된 모듈인 **tf.data**의 기능 활용한 예제를 확인해 보자.\n",
    "* tf.data에는 다양한 데이터 접근 방식이 존재하는데, 여기서 선택한 기능은 사용법이 직관적인 tf.data.Dataset.from_tensor_slices다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = ['너 오늘 이뻐 보인다',\n",
    "          '나는 오늘 기분이 더러워',\n",
    "          '끝내주는데, 좋은 일이 있나봐',\n",
    "          '나 좋은 일이 생겼어',\n",
    "          '아 오늘 진짜 짜증나',\n",
    "          '환상적인데, 정말 좋은거 같아']\n",
    "\n",
    "label = [[1], [0], [1], [1], [0], [1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 아래는 간단하게 설명하면 텍스트로 구성된 데이터에서 각 단어를 단어의 인덱스로 바꾼 것이다. 즉, 텍스트 데이터를 수치화한 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(samples)\n",
    "sequences = tokenizer.texts_to_sequences(samples)\n",
    "\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 아래 결과를 보면 기존의 텍스트로 구성된 데이터가 정수 배열로 바뀐 것을 확인할 수 있다. 여기서 각 정수값은 각 단어의 인덱스를 나타내는데, 각 단어의 인덱스 값은 아래에서 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수치화된 텍스트 데이터: \n",
      " [[4, 1, 5, 6], [7, 1, 8, 9], [10, 2, 3, 11], [12, 2, 3, 13], [14, 1, 15, 16], [17, 18, 19, 20]]\n",
      "각 단어의 인덱스: \n",
      " {'오늘': 1, '좋은': 2, '일이': 3, '너': 4, '이뻐': 5, '보인다': 6, '나는': 7, '기분이': 8, '더러워': 9, '끝내주는데': 10, '있나봐': 11, '나': 12, '생겼어': 13, '아': 14, '진짜': 15, '짜증나': 16, '환상적인데': 17, '정말': 18, '좋은거': 19, '같아': 20}\n",
      "라벨: [[1], [0], [1], [1], [0], [1]]\n"
     ]
    }
   ],
   "source": [
    "# 전처리한 데이터 구조 확인하기\n",
    "print(\"수치화된 텍스트 데이터: \\n\", sequences)\n",
    "print(\"각 단어의 인덱스: \\n\", word_index)\n",
    "print(\"라벨:\", label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **tf.data.Dataset.from_tensor_slices** 함수는 주어진 데이터 sequences와 label을 묶어서 조각으로 만들고 함께 사용할 수 있게 해준다. 그 다음 이렇게 정의한 데이터셋에 대해 **make_one_shot_iterator** 함수를 아용하는데, 이 함수는 데이터를 하나씩 사용할 수 있게 만들어준다. 이제 데이터가 이터레이터 형식으로 정으되어 있는데, 이터레이터의 **get_next** 함수를 사용하면 데이터가 하나씩 나오게 되는 구조이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.data를 활용하여 처리하기\n",
    "dataset = tf.data.Dataset.from_tensor_slices((sequences, label))\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_data = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([4, 1, 5, 6]), array([1]))\n",
      "(array([7, 1, 8, 9]), array([0]))\n",
      "(array([10,  2,  3, 11]), array([1]))\n",
      "(array([12,  2,  3, 13]), array([1]))\n",
      "(array([14,  1, 15, 16]), array([0]))\n",
      "(array([17, 18, 19, 20]), array([1]))\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    while True:\n",
    "        try:\n",
    "            print(sess.run(next_data))\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 아래는 배치 크기를 2로 설정한 후 데이터를 불러온 결과, 한 번에 2개의 데이터가 나오는 것을 확인할 수 있다. 배치 처리한 부분을 보면 매우 간단하게 정의한 dataset의 batch 함수를 통해 배치 크기를 설정해 주기만 하면 배치 설정이 끝난다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[4, 1, 5, 6],\n",
      "       [7, 1, 8, 9]]), array([[1],\n",
      "       [0]]))\n",
      "(array([[10,  2,  3, 11],\n",
      "       [12,  2,  3, 13]]), array([[1],\n",
      "       [1]]))\n",
      "(array([[14,  1, 15, 16],\n",
      "       [17, 18, 19, 20]]), array([[0],\n",
      "       [1]]))\n"
     ]
    }
   ],
   "source": [
    "# 배치 크기 조절\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((sequences, label))\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_data = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    while True:\n",
    "        try:\n",
    "            print(sess.run(next_data))\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 아래의 결과를 보면 기존에 출력했던 순서와 다르게 데이터가 나온 것을 확인할 수 있다. 기본적으로 tf.data는 기존 데이터의 순서와 동일하게 데이터를 불러오는 구조인데, 이렇게 dataset에 셔플 함수를 사용하면 임의의 순서대로 데이터를 불러오는 구조가 된다. 셔플 함수를 적용할 때 인자 값으로는 데이터의 전체 길이를 넣으면 된다.\n",
    "* 셔플 처리는 이후 모델의 성능에 크게 기여할 수 있기 때문에 매우 중요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([12,  2,  3, 13]), array([1]))\n",
      "(array([14,  1, 15, 16]), array([0]))\n",
      "(array([10,  2,  3, 11]), array([1]))\n",
      "(array([4, 1, 5, 6]), array([1]))\n",
      "(array([17, 18, 19, 20]), array([1]))\n",
      "(array([7, 1, 8, 9]), array([0]))\n"
     ]
    }
   ],
   "source": [
    "# 셔플\n",
    "dataset = tf.data.Dataset.from_tensor_slices((sequences, label))\n",
    "# 데이터 전체의 길이 적용\n",
    "dataset = dataset.shuffle(len(sequences))\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_data = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    while True:\n",
    "        try:\n",
    "            print(sess.run(next_data))\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 데이터로 모델을 학습시킬 때 데이터를 한 번씩만 사용하는 것이 아니라 여러번 사용해야 한다. 전체 데이터를 몇 번 사용하는지를 지칭하는 말이 에폭(Epoch)이다. 기존의 방법대로 tf.data를 사용하게 되면 데이터가 한 번씩만 사용되고 더 이상 데이터를 불러오지 않는데, 데이터가 여러 번 반복하도록 설정하면 정의한 만큼 데이터를 계속 불러올 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([4, 1, 5, 6]), array([1]))\n",
      "(array([7, 1, 8, 9]), array([0]))\n",
      "(array([10,  2,  3, 11]), array([1]))\n",
      "(array([12,  2,  3, 13]), array([1]))\n",
      "(array([14,  1, 15, 16]), array([0]))\n",
      "(array([17, 18, 19, 20]), array([1]))\n",
      "(array([4, 1, 5, 6]), array([1]))\n",
      "(array([7, 1, 8, 9]), array([0]))\n",
      "(array([10,  2,  3, 11]), array([1]))\n",
      "(array([12,  2,  3, 13]), array([1]))\n",
      "(array([14,  1, 15, 16]), array([0]))\n",
      "(array([17, 18, 19, 20]), array([1]))\n"
     ]
    }
   ],
   "source": [
    "# 에폭\n",
    "EPOCH = 2\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((sequences, label))\n",
    "dataset = dataset.repeat(EPOCH)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_data = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    while True:\n",
    "        try:\n",
    "            print(sess.run(next_data))\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 모델에 따라 입력값이 하나가 아니라 두개 이상이 될 수도 있는데, 이때 라벨을 제외한 나머지 데이터를 하나의 입력값으로 묶기 위해 매핑(Mapping) 과정을 거쳐야 한다.\n",
    "* 아래의 불러온 데이터를 보면 입력 데이터가 'x'라는 키 값을 가지고 있는 딕셔너리 구조다. 매핑 함수를 저으이한 후 dataset의 map 함수에 저으이한 매핑 함수를 적용해서 사용했다. 여기서는 하나의 입력값만 사용했기 때문에 딕셔너리 안에 하나의 값만 존재하는데, 만약 두 객 이상의 입력값이 존재한다면 두 번째 처럼 미팽 함수를 정의해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'x': array([4, 1, 5, 6])}, array([1]))\n",
      "({'x': array([7, 1, 8, 9])}, array([0]))\n",
      "({'x': array([10,  2,  3, 11])}, array([1]))\n",
      "({'x': array([12,  2,  3, 13])}, array([1]))\n",
      "({'x': array([14,  1, 15, 16])}, array([0]))\n",
      "({'x': array([17, 18, 19, 20])}, array([1]))\n"
     ]
    }
   ],
   "source": [
    "# 입력값 1개\n",
    "def mapping_fn(X, Y = None):\n",
    "    input = {'x': X}\n",
    "    label = Y\n",
    "    return input, label\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((sequences, label))\n",
    "dataset = dataset.map(mapping_fn)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_data = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    while True:\n",
    "        try:\n",
    "            print(sess.run(next_data))\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력값 2개 이상\n",
    "def mapping_fn(X1, X2, Y = None):\n",
    "    input = {'x1': X1, 'x2': X2}\n",
    "    label = Y\n",
    "    return input, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'x': array([[ 7,  1,  8,  9],\n",
      "       [17, 18, 19, 20]])}, array([[0],\n",
      "       [1]]))\n",
      "({'x': array([[14,  1, 15, 16],\n",
      "       [10,  2,  3, 11]])}, array([[0],\n",
      "       [1]]))\n",
      "({'x': array([[ 4,  1,  5,  6],\n",
      "       [12,  2,  3, 13]])}, array([[1],\n",
      "       [1]]))\n",
      "({'x': array([[17, 18, 19, 20],\n",
      "       [14,  1, 15, 16]])}, array([[1],\n",
      "       [0]]))\n",
      "({'x': array([[7, 1, 8, 9],\n",
      "       [4, 1, 5, 6]])}, array([[0],\n",
      "       [1]]))\n",
      "({'x': array([[10,  2,  3, 11],\n",
      "       [12,  2,  3, 13]])}, array([[1],\n",
      "       [1]]))\n"
     ]
    }
   ],
   "source": [
    "# 배치, 셔플, 반복, 매핑 하나로 묶기\n",
    "BATCH_SIZE = 2\n",
    "EPOCH = 2\n",
    "\n",
    "def mapping_fn(X, Y = None):\n",
    "    input = {'x': X}\n",
    "    label = Y\n",
    "    return input, label\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((sequences, label))\n",
    "dataset = dataset.map(mapping_fn)\n",
    "dataset = dataset.shuffle(len(sequences))\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.repeat(EPOCH)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_data = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    while True:\n",
    "        try:\n",
    "            print(sess.run(next_data))\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **에스티메이터(Estimator)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 딥러닝 모델을 최대한 빠르게 실험해보고 다양한 모델을 적용해야 하는 연구자와 개발자들은 다른 부분들 보다는 모델 구현에 집중할 수 있는 환경이 중요하다. 이러한 욕구를 충족시켜줄 수 있는 기능이 텐서플로의 에스티메이터이다.\n",
    "* 에스티메이터는 고수준(High Level) API로 모델 구현에만 집중할 수 있는 환경을 제공한다. 모델 구현 외의 학습(Train), 검증(Evaluate), 예측(Predict)에 필요한 부가적인 구현들은 Estimator의 함수를 사용함으로써 손쉽게 사용할 수 있다. 또한 모든 검증과 평가가 끝난 모델을 사용하기 위한 모델 배포(Export) 역시 간단하게 구현할 수 있다.\n",
    "    1. 학습(Train): 정의한 모델 파라미터에 대해 학습한다.\n",
    "    2. 평가(Evaluate): 학습한 모델에 대한 성능을 측정한다.\n",
    "    3. 예측(Predict): 모델을 통해 입력값에 대한 예측값을 받는다.\n",
    "    4. 배포(Export): 사용할 모델을 바이너리 파일로 출력한다.\n",
    "* 에스티메이터에는 선형 회귀, 선형 분류, 심층 신경망 분류기, 심층 신경망 회귀 모델 등 기본적인 모델이 이미 구현돼 있어서 모델을 구현할 필요없이 바로 사용할 수 있다.\n",
    "---\n",
    "* 에스티메이터를 구현하기 위해서는 기본적으로 두 가지 함수를 구현해야 한다. 사용할 모델을 구현한 모델 함수와 모델에 적용될 데이터를 에스티메이터에 전달하기 위한 데이터 입력 함수를 구현해야 한다. 두 함수 모두 에스티메이터를 통해 올바르게 동작하기 위해서는 정해진 형식을 맞춰서 구현해야 한다. 우선 모델 함수의 경우 아래와 같은 형식으로 구현해야 한다.\n",
    "        def model_fn(features, labels, mode, params, config):\n",
    "            # 모델 구현 부분\n",
    "            return tf.estimator.EstimatorSpec()\n",
    "            \n",
    "    1. features (필수사항): 모델에 적용되는 입력값을 의미한다. 하나의 텐서 자료형(tf.Tensor) 혹은 딕셔너리 자료형이어야 한다. 학습, 검증, 예측 과정 모두에 사용된다.\n",
    "    2. labels (필수사항): 모델의 정답 라벨값을 의미한다. 하나의 텐서 자료형(tf.Tensor) 혹은 딕셔너리 자료형이어야 한다. 예측 과정에서는 라벨이 존재하지 않기 때문에 Estimator에서 자동으로 이 값이 들어오지 않는다.\n",
    "    3. mode (선택사항): 현재 모델 함수가 실행된 모드(학습, 검증, 예측)를 의미한다.\n",
    "    4. params (선택사항): 모델에 적용될 부가적인 하이퍼파라미터 값을 의미한다. 딕셔너리 자료형이어야 한다.\n",
    "    5. config (선택사항): 모델에 적용할 설정값을 의미한다.\n",
    "위의 5개의 인자 중에서 features와 labels는 필수적으로 인자로 받아야 한다. 그리고 나머지 3개는 필요에 따라 선택적으로 받을 수 있다.\n",
    "---\n",
    "* 에스티메이터 객체의 경우 아래와 같이 생성한다.\n",
    "        estimator = tf.estimator.Estimator(model_fn = model_fn, model_dir = ...,\n",
    "                                            configs = ..., params = ...)\n",
    "* 객체 생성 시 필요한 인자는 모델 함수와 모델의 변수값 등이 저장되는 체크포인트(Check Point) 파일이 저장될 경로, 그리고 모델의 설정값인 configs와 하이퍼파라미터인 params를 넣어주면 된다. 모델 함수(model_fn)의 경우 필수적으로 넣어줘야 하고, 나머지 값들은 필요에 따라 선택적으로 넣어주면 된다. 이렇게 생성한 객체는 이제 학습, 검증, 예측을 위한 모든 준비가 끝난다. 아래와 같이 객체의 함수를 사용해 실행할 수 있다.\n",
    "        # 모델 학습\n",
    "        estimator.train(input_fn = ...)\n",
    "        \n",
    "        # 학습한 모델 검증\n",
    "        estimator.evaluate(input_fn = ...)\n",
    "        \n",
    "        # 학습한 모델을 통한 예측\n",
    "        estimator.predict(input_fn = ...)\n",
    "---\n",
    "* 마지막으로 각 함수를 보면 알 수 있듯이 입력 함수를 인자로 넣어줘야 한다. 아래와 같이 데이터에 맞게 입력 함수를 구현하면 된다.\n",
    "        def train_input_fn():\n",
    "            \n",
    "            # 데이터 파이프라인 구현 부분\n",
    "            \n",
    "            return features, labels\n",
    "데이터 파이프라인 구현 부분에는 데이터의 셔플, 배치, 반복 등의 기능들이 들어갈 것이다. 그리고 입력 함수의 경우 보통 학습, 검증, 예측 상황에 맞는 기능들이 모두 다르기 떄문에 각 입력 함수를 따로 구현한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import preprocessing\n",
    "\n",
    "samples = ['너 오늘 이뻐 보인다',\n",
    "          '나는 오늘 기분이 더러워',\n",
    "          '끝내주는데, 좋은 일이 있나봐',\n",
    "          '나 좋은 일이 생겼어',\n",
    "          '아 오늘 진짜 짜증나',\n",
    "          '환상적인데, 정말 좋은거 같아']\n",
    "\n",
    "labels = [[1], [0], [1], [1], [0], [1]]\n",
    "\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(samples)\n",
    "sequences = tokenizer.texts_to_sequences(samples)\n",
    "\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 아래에서 tf.data의 반복과 셔플 기능을 사용한다. 정의한 에폭(Epoch) 크기만큼 데이터를 반복시켜서 학습하게 하고, 셔플 기능을 추가해 모델이 학습을 잘 할 수 있게 한다. 그리고 데이터 입력 함수의 반환값은 이터레이터의 get_next 함수를 사용해서 입력값과 라벨값을 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 100\n",
    "\n",
    "def train_input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((sequences, labels))\n",
    "    dataset = dataset.repeat(EPOCH)\n",
    "    dataset = dataset.batch(1)\n",
    "    dataset = dataset.shuffle(len(sequences))\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    return iterator.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 아래는 모델 함수를 정의한 것이다. 모델 함수를 구현하면 에스티메이터를 사용해서 모델을 학습할 수 있다.\n",
    "\n",
    "    1. 우선 모델 함수에서 사용될 상숫값을 정의해준 후 모델 함수를 구현한다. 정의한 상숫값은 전체 단어 개수와 임베딩 벡터의 크기를 의미한다. 다음으로 모델 함수를 정의하는데 인자로 입력값과 라벨 그리고 현재 모델 함수가 실행되는 상태인 모드값을 받는다. 그리고 현재 현재 실행된 모드가 어떤 상태인지 확인하기 위한 상숫값인 TRAIN, EVAL, PREDICT를 정의한다. 해당하는 상태의 상숫값이 True로 설정될 것이다.\n",
    "    2. 그 다음은 모델 구현이다. 우선 입력값을 임베딩 벡터 형태로 만들어 준 후 텐서플로의 reduce_mean 함수를 통해 평균을 구해서 하나의 입력 벡터로 만들어 준다. 이 입력값을 Dense를 사용해 은닉층을 거쳐 출력값을 만든다. 최종적으로 나온 출력값에 시그모이드 함수를 적용해 0과 1 사이의 값으로 만들면 모델의 최종 출력값이 나온다.\n",
    "    3. 마지막으로 학습 상태일 때 모델을 학습할 수 있도록 손실(loss) 값과 옵티마이저(optimizer)를 설정해야 한다. 손실 함수는 평균 제곱 오차(Mean squared error)를 이용하고 옵티마이저의 경우 아담(Adam) 옵티마이저를 사용한다. 이렇게 구한 두 값을 학습 모드인 경우 EstimatorSpec의 인자값으로 반환하면 모델 함수 구현이 끝난다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(word_index) + 1\n",
    "EMB_SIZE = 128\n",
    "\n",
    "def model_fn(features, labels, mode):\n",
    "    \n",
    "    TRAIN = mode == tf.estimator.ModeKeys.TRAIN\n",
    "    EVAL = mode == tf.estimator.ModeKeys.EVAL\n",
    "    PREDICT = mode == tf.estimator.ModeKeys.PREDICT\n",
    "    \n",
    "    embed_input = tf.keras.layers.Embedding(VOCAB_SIZE, EMB_SIZE)(features)\n",
    "    embed_input = tf.reduce_mean(embed_input, axis = 1)\n",
    "    \n",
    "    hidden_layer = tf.keras.layers.Dense(128, activation = tf.nn.relu)(embed_input)\n",
    "    output_layer = tf.keras.layers.Dense(1)(hidden_layer)\n",
    "    output = tf.nn.sigmoid(output_layer)\n",
    "    \n",
    "    loss = tf.losses.mean_squared_error(output, labels)\n",
    "    \n",
    "    if TRAIN:\n",
    "        global_step = tf.train.get_global_step()\n",
    "        train_op = tf.train.AdamOptimizer(1e-3).minimize(loss, global_step)\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(\n",
    "                mode = mode,\n",
    "                train_op = train_op,\n",
    "                loss = loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './data_out/checkpoint/dnn', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000018C86AD12E8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From C:\\Users\\young\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\young\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./data_out/checkpoint/dnn\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.25628775, step = 1\n",
      "INFO:tensorflow:global_step/sec: 202.22\n",
      "INFO:tensorflow:loss = 0.0036707544, step = 101 (0.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 490.544\n",
      "INFO:tensorflow:loss = 0.00072819286, step = 201 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 658.863\n",
      "INFO:tensorflow:loss = 0.00053892494, step = 301 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 520.962\n",
      "INFO:tensorflow:loss = 8.6513166e-05, step = 401 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 587.796\n",
      "INFO:tensorflow:loss = 0.000180607, step = 501 (0.171 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 600 into ./data_out/checkpoint/dnn\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4.0207276e-05.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x18c86ad12b0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_OUT_PATH = './data_out/'\n",
    "\n",
    "import os\n",
    "\n",
    "if not os.path.exists(DATA_OUT_PATH):\n",
    "    os.makedirs(DATA_OUT_PATH)\n",
    "    \n",
    "estimator = tf.estimator.Estimator(model_fn = model_fn, model_dir = DATA_OUT_PATH + 'checkpoint/dnn')\n",
    "estimator.train(train_input_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
